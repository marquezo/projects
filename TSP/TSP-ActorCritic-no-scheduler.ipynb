{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added critic to the code found in \n",
    "https://github.com/higgsfield/np-hard-deep-reinforcement-learning/blob/master/Neural%20Combinatorial%20Optimization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a set of 2D coordinates of length 'num_samples'\n",
    "class TSPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, num_nodes, num_samples, random_seed=111):\n",
    "        super(TSPDataset, self).__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        self.data_set = []\n",
    "        for l in range(num_samples):\n",
    "            x = torch.FloatTensor(2, num_nodes).uniform_(0, 1)\n",
    "            self.data_set.append(x)\n",
    "\n",
    "        self.size = len(self.data_set)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000000\n",
    "val_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20_dataset = TSPDataset(20, train_size)\n",
    "val_20_dataset   = TSPDataset(20, val_size)\n",
    "\n",
    "train_50_dataset = TSPDataset(50, train_size)\n",
    "val_50_dataset   = TSPDataset(50, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dataset = TSPDataset(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, use_tanh=False, C=10, name='Bahdanau', use_cuda=USE_CUDA):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.use_tanh = use_tanh\n",
    "        self.C = C\n",
    "        self.name = name\n",
    "        \n",
    "        if name == 'Bahdanau':\n",
    "            self.W_query = nn.Linear(hidden_size, hidden_size)\n",
    "            self.W_ref   = nn.Conv1d(hidden_size, hidden_size, 1, 1)\n",
    "\n",
    "            V = torch.FloatTensor(hidden_size)\n",
    "            if use_cuda:\n",
    "                V = V.cuda()  \n",
    "            self.V = nn.Parameter(V)\n",
    "            self.V.data.uniform_(-(1. / math.sqrt(hidden_size)) , 1. / math.sqrt(hidden_size))\n",
    "            \n",
    "        \n",
    "    def forward(self, query, ref):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            query: [batch_size x hidden_size]\n",
    "            ref:   ]batch_size x seq_len x hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = ref.size(0)\n",
    "        seq_len    = ref.size(1)\n",
    "        \n",
    "        if self.name == 'Bahdanau':\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "            query = self.W_query(query).unsqueeze(2)  # [batch_size x hidden_size x 1]\n",
    "            ref   = self.W_ref(ref)  # [batch_size x hidden_size x seq_len] \n",
    "            expanded_query = query.repeat(1, 1, seq_len) # [batch_size x hidden_size x seq_len]\n",
    "            V = self.V.unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1) # [batch_size x 1 x hidden_size]\n",
    "            logits = torch.bmm(V, F.tanh(expanded_query + ref)).squeeze(1)\n",
    "            \n",
    "        elif self.name == 'Dot':\n",
    "            query  = query.unsqueeze(2)\n",
    "            logits = torch.bmm(ref, query).squeeze(2) #[batch_size x seq_len x 1]\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            logits = self.C * F.tanh(logits)\n",
    "        else:\n",
    "            logits = logits  \n",
    "        return ref, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, use_cuda=USE_CUDA):\n",
    "        super(GraphEmbedding, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.embedding = nn.Parameter(torch.FloatTensor(input_size, embedding_size)) \n",
    "        self.embedding.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        embedding = self.embedding.repeat(batch_size, 1, 1)  \n",
    "        embedded = []\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        for i in range(seq_len):\n",
    "            embedded.append(torch.bmm(inputs[:, :, :, i].float(), embedding))\n",
    "        embedded = torch.cat(embedded, 1)\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            num_processing,\n",
    "            n_glimpses,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.num_processing = num_processing\n",
    "        self.use_cuda       = use_cuda\n",
    "    \n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        #self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)  \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=True, name='Bahdanau', use_cuda=use_cuda) \n",
    "            \n",
    "        self.fc1.weight = torch.nn.init.uniform(self.fc1.weight, -0.08, 0.08)  \n",
    "        self.fc2.weight = torch.nn.init.uniform(self.fc2.weight, -0.08, 0.08)        \n",
    "        \n",
    "        for p in self.encoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)        \n",
    "            \n",
    "    def forward(self, inputs, input_embedded):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"        \n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(input_embedded)       \n",
    "        \"\"\"encoder_outputs: [batch_size x seq_len x hidden_size]\"\"\"                \n",
    "       \n",
    "        #The first input to the decoder is the last hidden state\n",
    "        #decoder_input = torch.t(hidden) #Batch size has to be the first dimension, so swap first and second dimensions\n",
    "        \n",
    "        #Init decoder's hidden and reuse the encoder's context        \n",
    "        #hidden = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "        #context = Variable(torch.zeros(context.size()))\n",
    "        \n",
    "#         print (decoder_input.size())\n",
    "        \n",
    "        query = torch.t(hidden).squeeze()        \n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(self.num_processing):                        \n",
    "            \n",
    "            #_, (hidden, context) = self.decoder(decoder_input, (hidden, context))\n",
    "            \n",
    "            #query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)            \n",
    "            \n",
    "            #Do the glimpse\n",
    "            ref, logits = self.glimpse(query, encoder_outputs)\n",
    "            #logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            query = torch.bmm(ref, F.softmax(logits, dim=1).unsqueeze(2)).squeeze(2)           \n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = query#.unsqueeze(1)\n",
    "            \n",
    "        #Do fully connected part   TODO: batch norm \n",
    "        output = self.fc1(query)\n",
    "        output = F.relu(output)\n",
    "        output = self.fc2(output)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(PointerNet, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.use_cuda       = use_cuda\n",
    "        \n",
    "        \n",
    "        self.embedding = GraphEmbedding(2, embedding_size, use_cuda=use_cuda)\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.pointer = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        \n",
    "        self.decoder_start_input = nn.Parameter(torch.FloatTensor(embedding_size))\n",
    "        self.decoder_start_input.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "        for p in self.encoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)\n",
    "\n",
    "        for p in self.decoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)        \n",
    "        \n",
    "    \"\"\"\n",
    "    idxs: indeces that were previously chosen\n",
    "    logits: probabilities for current step\n",
    "    \"\"\"\n",
    "    def apply_mask_to_logits(self, logits, mask, idxs): \n",
    "        batch_size = logits.size(0)\n",
    "        clone_mask = mask.clone()\n",
    "\n",
    "        if idxs is not None:\n",
    "            clone_mask[[i for i in range(batch_size)], idxs.data] = 1\n",
    "            logits[clone_mask] = -np.inf\n",
    "        return logits, clone_mask\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(embedded)        \n",
    "        \n",
    "        prev_probs = []\n",
    "        prev_idxs = []\n",
    "        mask = torch.zeros(batch_size, seq_len).byte()\n",
    "        if self.use_cuda:\n",
    "            mask = mask.cuda()\n",
    "            \n",
    "        idxs = None\n",
    "       \n",
    "        #The first input to the decoder is learned, as in the paper\n",
    "        decoder_input = self.decoder_start_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(seq_len):                                        \n",
    "                \n",
    "            _, (hidden, context) = self.decoder(decoder_input.unsqueeze(1), (hidden, context))\n",
    "            \n",
    "            query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)\n",
    "            \n",
    "            for i in range(self.n_glimpses):\n",
    "                ref, logits = self.glimpse(query, encoder_outputs)\n",
    "                logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "                query = torch.bmm(ref, F.softmax(logits, dim=1).unsqueeze(2)).squeeze(2)                 \n",
    "                \n",
    "            _, logits = self.pointer(query, encoder_outputs)\n",
    "            logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            \n",
    "            #[batch size x seq_len]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            #Give me the index that will be chosen: [batch_size]\n",
    "            idxs = probs.multinomial().squeeze(1)\n",
    "            \n",
    "            for old_idxs in prev_idxs:\n",
    "                if old_idxs.eq(idxs).data.any():\n",
    "                    print seq_len\n",
    "                    print(' RESAMPLE!')\n",
    "                    idxs = probs.multinomial().squeeze(1)\n",
    "                    break\n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = embedded[range(batch_size), idxs.data, :] \n",
    "            \n",
    "            prev_probs.append(probs)\n",
    "            prev_idxs.append(idxs)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return prev_probs, prev_idxs, embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialRL(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,        \n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(CombinatorialRL, self).__init__()       \n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.actor = PointerNet(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                seq_len,\n",
    "                n_glimpses,\n",
    "                tanh_exploration,\n",
    "                use_tanh,\n",
    "                attention,\n",
    "                use_cuda)\n",
    "        \n",
    "        self.critic = Critic(embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            seq_len=seq_len,\n",
    "            num_processing=3,\n",
    "            n_glimpses=n_glimpses,\n",
    "            use_cuda=use_cuda)\n",
    "\n",
    "    #Returns a vector of size equal to the mini-batch size\n",
    "    def reward(self, sample_solution, USE_CUDA=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_solution list of length 'seq_len' of [batch_size x input_size (2 since doing 2D coordinates)]\n",
    "        \"\"\"\n",
    "        batch_size = sample_solution[0].size(0)\n",
    "        n = len(sample_solution)\n",
    "\n",
    "        tour_len = Variable(torch.zeros([batch_size]))\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tour_len = tour_len.cuda()\n",
    "\n",
    "        for i in range(n - 1):\n",
    "            tour_len += torch.norm(sample_solution[i] - sample_solution[i + 1], dim=1)\n",
    "\n",
    "        tour_len += torch.norm(sample_solution[n - 1] - sample_solution[0], dim=1)\n",
    "\n",
    "        return tour_len\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch_size, input_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        input_size = inputs.size(1) #2 because we are doing 2D coordinates\n",
    "        seq_len    = inputs.size(2)        \n",
    "                \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        probs, action_idxs, input_embedded = self.actor(inputs)\n",
    "                        \n",
    "        critic_evals = self.critic(inputs, input_embedded)\n",
    "        \n",
    "#         print (\"Combinatorial RL (inputs)\")\n",
    "#         print (inputs)\n",
    "        #print (\"Combinatorial RL (action_idxs.size): \", action_idxs)\n",
    "       \n",
    "        actions = []\n",
    "        \n",
    "        \"\"\"\n",
    "        Transpose the inputs to have [batch_size, seq_len, input_size]\n",
    "        \"\"\"\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        \n",
    "        #List of size seq_len\n",
    "        for action_id in action_idxs:\n",
    "            actions.append(inputs[range(batch_size), action_id.data, :])\n",
    "            \n",
    "        #actions now has the coordinates in the solution            \n",
    "        action_probs = []    \n",
    "        #List of size seq_len\n",
    "        for prob, action_id in zip(probs, action_idxs):\n",
    "            #We want to know the probability of taking each action (picking city) in the solution\n",
    "            action_probs.append(prob[range(batch_size), action_id.data])\n",
    "\n",
    "        #R is [batch_size x 1]\n",
    "        R = self.reward(actions, self.use_cuda)\n",
    "        \n",
    "        return R, action_probs, actions, action_idxs, critic_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size    = 128\n",
    "n_glimpses = 1\n",
    "tanh_exploration = 10\n",
    "use_tanh = True\n",
    "\n",
    "beta = 0.9\n",
    "max_grad_norm = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        20,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_50_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        50,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_5_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        5,\n",
    "        n_glimpses,\n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention='Dot',\n",
    "        use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, model, train_dataset, val_dataset, batch_size=128, threshold=None, max_grad_norm=2.):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset   = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        self.val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        \n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "        self.train_tour = []\n",
    "        self.val_tour   = []\n",
    "        \n",
    "        self.epochs = 0\n",
    "    \n",
    "    def train_and_validate(self, n_epochs, lr_actor, lr_critic, scheduler_step, scheduler_gamma):\n",
    "        \n",
    "        self.actor_optim   = optim.Adam(self.model.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_optim  = optim.Adam(self.model.critic.parameters(), lr=lr_critic)\n",
    "#         self.scheduler_actor = optim.lr_scheduler.StepLR(self.actor_optim, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "#         self.scheduler_critic = optim.lr_scheduler.StepLR(self.critic_optim, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "        \n",
    "        critic_exp_mvg_avg = torch.zeros(1)\n",
    "        critic_loss_criterion = torch.nn.MSELoss()        \n",
    "        \n",
    "        if USE_CUDA: \n",
    "            critic_exp_mvg_avg = critic_exp_mvg_avg.cuda()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_id, sample_batch in enumerate(self.train_loader):\n",
    "                self.model.train()\n",
    "                \n",
    "#                 self.scheduler_actor.step()\n",
    "#                 self.scheduler_critic.step()\n",
    "                \n",
    "                inputs = Variable(sample_batch)\n",
    "                \n",
    "                if USE_CUDA:\n",
    "                    inputs = inputs.cuda()\n",
    "\n",
    "                #Model is combinatorial\n",
    "                R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "\n",
    "                if batch_id == 0:\n",
    "                    critic_exp_mvg_avg = R.mean()\n",
    "                else:\n",
    "                    critic_exp_mvg_avg = (critic_exp_mvg_avg * beta) + ((1. - beta) * R.mean())\n",
    "\n",
    "                #Vector of length equal to the mini-batch size: Q(s,a) - V(s)\n",
    "                #advantage = R - critic_exp_mvg_avg                \n",
    "                advantage = R.unsqueeze(1) - values\n",
    "                \n",
    "                #print (\"Advantage function: \", R.mean() - values.mean())\n",
    "\n",
    "                logprobs = 0\n",
    "                for prob in probs: \n",
    "                    logprob = torch.log(prob)\n",
    "                    logprobs += logprob\n",
    "                    \n",
    "                #logprobs[logprobs < -1000] = 0. #Works with PyTorch 2.0\n",
    "                                \n",
    "                #For Pytorch 3.0                                \n",
    "                if logprobs.data[0] < -1000:\n",
    "                    print (logprobs.data[0])\n",
    "                    logprobs = Variable(torch.FloatTensor([0.]), requires_grad=True)\n",
    "\n",
    "                reinforce = advantage * logprobs\n",
    "                actor_loss = reinforce.mean()\n",
    "\n",
    "                self.actor_optim.zero_grad()                \n",
    "                actor_loss.backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm(self.model.actor.parameters(),\n",
    "                                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.actor_optim.step()\n",
    "                \n",
    "                #Do critic gradient descent\n",
    "                self.critic_optim.zero_grad()\n",
    "                loss_critic = critic_loss_criterion(values, R.unsqueeze(1))\n",
    "                loss_critic.backward()\n",
    "                torch.nn.utils.clip_grad_norm(self.model.critic.parameters(),\n",
    "                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.critic_optim.step()\n",
    "                #print (\"Critic's loss: \", loss_critic.data[0])\n",
    "                \n",
    "                #critic_exp_mvg_avg = critic_exp_mvg_avg.detach()\n",
    "\n",
    "                self.train_tour.append(R.mean().data[0])\n",
    "\n",
    "                if batch_id % 100 == 0:\n",
    "                    self.plot(self.epochs)\n",
    "                    #print (\"Epoch {}, Batch {}: Tour length {}\".format(epoch, batch_id, R.mean().data[0]) )\n",
    "\n",
    "#                 if batch_id % 100 == 0:    \n",
    "\n",
    "#                     self.model.eval()\n",
    "#                     for val_batch in self.val_loader:\n",
    "#                         inputs = Variable(val_batch)\n",
    "                        \n",
    "#                         if USE_CUDA:\n",
    "#                             inputs = inputs.cuda()\n",
    "\n",
    "#                         R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "#                         self.val_tour.append(R.mean().data[0])\n",
    "\n",
    "            if self.threshold and self.train_tour[-1] < self.threshold:\n",
    "                print \"EARLY STOPPAGE!\"\n",
    "                break\n",
    "                \n",
    "            self.epochs += 1\n",
    "                \n",
    "    def plot(self, epoch):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train tour length: epoch %s reward %s' % (epoch, self.train_tour[-1] if len(self.train_tour) else 'collecting'))\n",
    "        plt.plot(self.train_tour)\n",
    "        plt.grid()\n",
    "#         plt.subplot(132)\n",
    "#         plt.title('val tour length: epoch %s reward %s' % (epoch, self.val_tour[-1] if len(self.val_tour) else 'collecting'))\n",
    "#         plt.plot(self.val_tour)\n",
    "#         plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_train = TrainModel(tsp_20_model, \n",
    "                        train_20_dataset, \n",
    "                        val_20_dataset, \n",
    "                        threshold=3.99)\n",
    "\n",
    "tsp_5_train = TrainModel(tsp_5_model, study_dataset,\n",
    "                        study_dataset, threshold=3.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    return recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "Exception socket.error: error(2, 'No such file or directory') in <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7ffabab3ff10>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2d525ffd8144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0mlr_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mscheduler_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                 scheduler_gamma=0.96)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-de286eb78a81>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(self, n_epochs, lr_actor, lr_critic, scheduler_step, scheduler_gamma)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 torch.nn.utils.clip_grad_norm(self.model.actor.parameters(),\n\u001b[1;32m     76\u001b[0m                                     float(self.max_grad_norm), norm_type=2)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsp_20_train.train_and_validate(n_epochs=5, \n",
    "                                lr_actor=0.0001, \n",
    "                                lr_critic=0.0001, \n",
    "                                scheduler_step=5000, \n",
    "                                scheduler_gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1481773266\n",
      "5.05194330215\n",
      "5.0458316803\n",
      "4.96701812744\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.72579431534\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319839478\n",
      "4.49319885792\n"
     ]
    }
   ],
   "source": [
    "def reward_single_input(sample_solution):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample_solution list of length 'seq_len' of [batch_size x input_size (2 since doing 2D coordinates)]\n",
    "    \"\"\"\n",
    "    n = sample_solution.size(0)\n",
    "    tour_len = 0\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        tour_len += torch.norm(sample_solution[i] - sample_solution[i + 1])\n",
    "\n",
    "    tour_len += torch.norm(sample_solution[n - 1] - sample_solution[0])\n",
    "\n",
    "    return tour_len\n",
    "\n",
    "def shuffle_tensor (tensor):\n",
    "    shuffle_indexes = torch.randperm(tensor.size(-1))\n",
    "    tensor_shuffled = torch.FloatTensor(tensor.t().size())\n",
    "    \n",
    "    for i in range(tensor.size(-1)):\n",
    "        tensor_shuffled[i] = tensor.t()[shuffle_indexes[i]]\n",
    "        \n",
    "    return tensor_shuffled.t()\n",
    "\n",
    "def create_graph(num_nodes):\n",
    "    x = torch.FloatTensor(2, num_nodes).uniform_(0, 1)\n",
    "    return x\n",
    "\n",
    "def active_search(input, model, num_candidates, batch_size, alpha=0.9, lr=0.0001):\n",
    "    \n",
    "    baseline = torch.zeros(1)\n",
    "    actor_optim = optim.Adam(model.actor.parameters(), lr=lr)\n",
    "    \n",
    "    #Create random solution\n",
    "    soln = shuffle_tensor(input)\n",
    "    soln_tour_length = reward_single_input(soln.t())\n",
    "    n = torch.ceil(torch.FloatTensor([num_candidates/batch_size]))\n",
    "    \n",
    "    for batch_id in range(n):\n",
    "    \n",
    "        shuffled_input = input.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "        #Shuffled the input for batch_size times\n",
    "        for i in range(batch_size):\n",
    "            shuffled_input[i] = shuffle_tensor(shuffled_input[i])\n",
    "\n",
    "        shuffled_input = Variable(shuffled_input)\n",
    "        R, probs, actions, action_idxs, critic_evals = model(shuffled_input)\n",
    "\n",
    "        # R is tensor of size batch_size\n",
    "        #Pick the shortest tour\n",
    "        idx_min_tour = np.argmin(R.data)\n",
    "        min_tour_length = R[idx_min_tour]   \n",
    "        \n",
    "        print (soln_tour_length)\n",
    "\n",
    "        if (min_tour_length.data[0] < soln_tour_length):\n",
    "            soln_tour_length = min_tour_length.data[0]\n",
    "            soln = torch.zeros((input.size(-1), 2))\n",
    "\n",
    "            #for seq len, get the new solution\n",
    "            for i in range(input.size(-1)):\n",
    "                soln[i] =  actions[i][idx_min_tour].data                 \n",
    "\n",
    "            #For some reason, these two are only equal up to a decimal\n",
    "    #         print reward_single_input(soln)\n",
    "    #         print min_tour_length.data        \n",
    "\n",
    "        if batch_id == 0:\n",
    "            baseline = R.mean()\n",
    "        else:\n",
    "            baseline = (baseline * alpha) + ((1. - alpha) * R.mean())\n",
    "        \n",
    "        advantage = R - baseline\n",
    "\n",
    "        logprobs = 0\n",
    "\n",
    "        for prob in probs: \n",
    "            logprob = torch.log(prob)\n",
    "            logprobs += logprob\n",
    "\n",
    "        if logprobs.data[0] < -1000:\n",
    "            logprobs = Variable(torch.FloatTensor([0.]), requires_grad=True)\n",
    "\n",
    "        reinforce = advantage * logprobs\n",
    "        actor_loss = reinforce.mean()\n",
    "\n",
    "        actor_optim.zero_grad()                \n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.actor.parameters(),\n",
    "                            1.0, norm_type=2)\n",
    "\n",
    "        actor_optim.step()\n",
    "\n",
    "    return soln\n",
    "\n",
    "    \n",
    "test_input = create_graph(20)\n",
    "soln = active_search(test_input, tsp_20_train.model, 10000, 128)\n",
    "\n",
    "#print soln\n",
    "print reward_single_input(soln)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
