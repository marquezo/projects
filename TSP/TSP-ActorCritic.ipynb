{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added critic to the code found in \n",
    "https://github.com/higgsfield/np-hard-deep-reinforcement-learning/blob/master/Neural%20Combinatorial%20Optimization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "#from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a set of 2D coordinates of length 'num_samples'\n",
    "class TSPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, num_nodes, num_samples, random_seed=111):\n",
    "        super(TSPDataset, self).__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        self.data_set = []\n",
    "        for l in range(num_samples):\n",
    "            x = torch.FloatTensor(2, num_nodes).uniform_(0, 1)\n",
    "            self.data_set.append(x)\n",
    "\n",
    "        self.size = len(self.data_set)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000000\n",
    "val_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20_dataset = TSPDataset(20, train_size)\n",
    "val_20_dataset   = TSPDataset(20, val_size)\n",
    "\n",
    "train_50_dataset = TSPDataset(50, train_size)\n",
    "val_50_dataset   = TSPDataset(50, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dataset = TSPDataset(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, use_tanh=False, C=10, name='Bahdanau', use_cuda=USE_CUDA):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.use_tanh = use_tanh\n",
    "        self.C = C\n",
    "        self.name = name\n",
    "        \n",
    "        if name == 'Bahdanau':\n",
    "            self.W_query = nn.Linear(hidden_size, hidden_size)\n",
    "            self.W_ref   = nn.Conv1d(hidden_size, hidden_size, 1, 1)\n",
    "\n",
    "            V = torch.FloatTensor(hidden_size)\n",
    "            if use_cuda:\n",
    "                V = V.cuda()  \n",
    "            self.V = nn.Parameter(V)\n",
    "            self.V.data.uniform_(-(1. / math.sqrt(hidden_size)) , 1. / math.sqrt(hidden_size))\n",
    "            \n",
    "        \n",
    "    def forward(self, query, ref):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            query: [batch_size x hidden_size]\n",
    "            ref:   ]batch_size x seq_len x hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = ref.size(0)\n",
    "        seq_len    = ref.size(1)\n",
    "        \n",
    "        if self.name == 'Bahdanau':\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "            query = self.W_query(query).unsqueeze(2)  # [batch_size x hidden_size x 1]\n",
    "            ref   = self.W_ref(ref)  # [batch_size x hidden_size x seq_len] \n",
    "            expanded_query = query.repeat(1, 1, seq_len) # [batch_size x hidden_size x seq_len]\n",
    "            V = self.V.unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1) # [batch_size x 1 x hidden_size]\n",
    "            logits = torch.bmm(V, F.tanh(expanded_query + ref)).squeeze(1)\n",
    "            \n",
    "        elif self.name == 'Dot':\n",
    "            query  = query.unsqueeze(2)\n",
    "            logits = torch.bmm(ref, query).squeeze(2) #[batch_size x seq_len x 1]\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            logits = self.C * F.tanh(logits)\n",
    "        else:\n",
    "            logits = logits  \n",
    "        return ref, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, use_cuda=USE_CUDA):\n",
    "        super(GraphEmbedding, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.embedding = nn.Parameter(torch.FloatTensor(input_size, embedding_size)) \n",
    "        self.embedding.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        embedding = self.embedding.repeat(batch_size, 1, 1)  \n",
    "        embedded = []\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        for i in range(seq_len):\n",
    "            embedded.append(torch.bmm(inputs[:, :, :, i].float(), embedding))\n",
    "        embedded = torch.cat(embedded, 1)\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            num_processing,\n",
    "            n_glimpses,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.num_processing = num_processing\n",
    "        self.use_cuda       = use_cuda\n",
    "    \n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        #self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)  \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=True, name='Bahdanau', use_cuda=use_cuda) \n",
    "            \n",
    "        self.fc1.weight = torch.nn.init.uniform(self.fc1.weight, -0.08, 0.08)  \n",
    "        self.fc2.weight = torch.nn.init.uniform(self.fc2.weight, -0.08, 0.08)        \n",
    "        \n",
    "        for p in self.encoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)        \n",
    "            \n",
    "    def forward(self, inputs, input_embedded):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"        \n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(input_embedded)       \n",
    "        \"\"\"encoder_outputs: [batch_size x seq_len x hidden_size]\"\"\"                \n",
    "       \n",
    "        #The first input to the decoder is the last hidden state\n",
    "        #decoder_input = torch.t(hidden) #Batch size has to be the first dimension, so swap first and second dimensions\n",
    "        \n",
    "        #Init decoder's hidden and reuse the encoder's context        \n",
    "        #hidden = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "        #context = Variable(torch.zeros(context.size()))\n",
    "        \n",
    "#         print (decoder_input.size())\n",
    "        \n",
    "        query = torch.t(hidden).squeeze()        \n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(self.num_processing):                        \n",
    "            \n",
    "            #_, (hidden, context) = self.decoder(decoder_input, (hidden, context))\n",
    "            \n",
    "            #query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)            \n",
    "            \n",
    "            #Do the glimpse\n",
    "            ref, logits = self.glimpse(query, encoder_outputs)\n",
    "            #logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            query = torch.bmm(ref, F.softmax(logits, dim=1).unsqueeze(2)).squeeze(2)           \n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = query#.unsqueeze(1)\n",
    "            \n",
    "        #Do fully connected part   TODO: batch norm \n",
    "        output = self.fc1(query)\n",
    "        output = F.relu(output)\n",
    "        output = self.fc2(output)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(PointerNet, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.use_cuda       = use_cuda\n",
    "        \n",
    "        \n",
    "        self.embedding = GraphEmbedding(2, embedding_size, use_cuda=use_cuda)\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.pointer = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        \n",
    "        self.decoder_start_input = nn.Parameter(torch.FloatTensor(embedding_size))\n",
    "        self.decoder_start_input.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "        for p in self.encoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)\n",
    "\n",
    "        for p in self.decoder.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant(p, 0)\n",
    "            else:\n",
    "                nn.init.uniform(p, -0.08, 0.08)        \n",
    "        \n",
    "    \"\"\"\n",
    "    idxs: indeces that were previously chosen\n",
    "    logits: probabilities for current step\n",
    "    \"\"\"\n",
    "    def apply_mask_to_logits(self, logits, mask, idxs): \n",
    "        batch_size = logits.size(0)\n",
    "        clone_mask = mask.clone()\n",
    "\n",
    "        if idxs is not None:\n",
    "            clone_mask[[i for i in range(batch_size)], idxs.data] = 1\n",
    "            logits[clone_mask] = -np.inf\n",
    "        return logits, clone_mask\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(embedded)        \n",
    "        \n",
    "        prev_probs = []\n",
    "        prev_idxs = []\n",
    "        mask = torch.zeros(batch_size, seq_len).byte()\n",
    "        if self.use_cuda:\n",
    "            mask = mask.cuda()\n",
    "            \n",
    "        idxs = None\n",
    "       \n",
    "        #The first input to the decoder is learned, as in the paper\n",
    "        decoder_input = self.decoder_start_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(seq_len):                                        \n",
    "                \n",
    "            _, (hidden, context) = self.decoder(decoder_input.unsqueeze(1), (hidden, context))\n",
    "            \n",
    "            query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)\n",
    "            \n",
    "            for i in range(self.n_glimpses):\n",
    "                ref, logits = self.glimpse(query, encoder_outputs)\n",
    "                logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "                query = torch.bmm(ref, F.softmax(logits, dim=1).unsqueeze(2)).squeeze(2)                 \n",
    "                \n",
    "            _, logits = self.pointer(query, encoder_outputs)\n",
    "            logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            \n",
    "            #[batch size x seq_len]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            #Give me the index that will be chosen: [batch_size]\n",
    "            idxs = probs.multinomial().squeeze(1)\n",
    "            \n",
    "            for old_idxs in prev_idxs:\n",
    "                if old_idxs.eq(idxs).data.any():\n",
    "                    print seq_len\n",
    "                    print(' RESAMPLE!')\n",
    "                    idxs = probs.multinomial().squeeze(1)\n",
    "                    break\n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = embedded[range(batch_size), idxs.data, :] \n",
    "            \n",
    "            prev_probs.append(probs)\n",
    "            prev_idxs.append(idxs)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return prev_probs, prev_idxs, embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialRL(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,        \n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(CombinatorialRL, self).__init__()       \n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.actor = PointerNet(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                seq_len,\n",
    "                n_glimpses,\n",
    "                tanh_exploration,\n",
    "                use_tanh,\n",
    "                attention,\n",
    "                use_cuda)\n",
    "        \n",
    "        self.critic = Critic(embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            seq_len=seq_len,\n",
    "            num_processing=3,\n",
    "            n_glimpses=n_glimpses,\n",
    "            use_cuda=use_cuda)\n",
    "\n",
    "    #Returns a vector of size equal to the mini-batch size\n",
    "    def reward(self, sample_solution, USE_CUDA=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_solution list of length 'seq_len' of [batch_size x input_size (2 since doing 2D coordinates)]\n",
    "        \"\"\"\n",
    "        batch_size = sample_solution[0].size(0)\n",
    "        n = len(sample_solution)\n",
    "\n",
    "        tour_len = Variable(torch.zeros([batch_size]))\n",
    "\n",
    "        if USE_CUDA:\n",
    "            tour_len = tour_len.cuda()\n",
    "\n",
    "        for i in range(n - 1):\n",
    "            tour_len += torch.norm(sample_solution[i] - sample_solution[i + 1], dim=1)\n",
    "\n",
    "        tour_len += torch.norm(sample_solution[n - 1] - sample_solution[0], dim=1)\n",
    "\n",
    "        return tour_len\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch_size, input_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        input_size = inputs.size(1) #2 because we are doing 2D coordinates\n",
    "        seq_len    = inputs.size(2)        \n",
    "                \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        probs, action_idxs, input_embedded = self.actor(inputs)\n",
    "                        \n",
    "        critic_evals = self.critic(inputs, input_embedded)\n",
    "        \n",
    "#         print (\"Combinatorial RL (inputs)\")\n",
    "#         print (inputs)\n",
    "        #print (\"Combinatorial RL (action_idxs.size): \", action_idxs)\n",
    "       \n",
    "        actions = []\n",
    "        \n",
    "        \"\"\"\n",
    "        Transpose the inputs to have [batch_size, seq_len, input_size]\n",
    "        \"\"\"\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        \n",
    "        #List of size seq_len\n",
    "        for action_id in action_idxs:\n",
    "            actions.append(inputs[range(batch_size), action_id.data, :])\n",
    "            \n",
    "        #actions now has the coordinates in the solution            \n",
    "        action_probs = []    \n",
    "        #List of size seq_len\n",
    "        for prob, action_id in zip(probs, action_idxs):\n",
    "            #We want to know the probability of taking each action (picking city) in the solution\n",
    "            action_probs.append(prob[range(batch_size), action_id.data])\n",
    "\n",
    "        #R is [batch_size x 1]\n",
    "        R = self.reward(actions, self.use_cuda)\n",
    "        \n",
    "        return R, action_probs, actions, action_idxs, critic_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size    = 128\n",
    "n_glimpses = 1\n",
    "tanh_exploration = 10\n",
    "use_tanh = True\n",
    "\n",
    "beta = 0.9\n",
    "max_grad_norm = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        20,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_50_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        50,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_5_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        5,\n",
    "        n_glimpses,\n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        attention='Dot',\n",
    "        use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, model, train_dataset, val_dataset, batch_size=128, threshold=None, max_grad_norm=2.):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset   = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        self.val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        \n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "        self.train_tour = []\n",
    "        self.val_tour   = []\n",
    "        \n",
    "        self.epochs = 0\n",
    "    \n",
    "    def train_and_validate(self, n_epochs, lr_actor, lr_critic, scheduler_step, scheduler_gamma):\n",
    "        \n",
    "        self.actor_optim   = optim.Adam(self.model.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_optim  = optim.Adam(self.model.critic.parameters(), lr=lr_critic)\n",
    "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.actor_optim, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.critic_optim, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "        \n",
    "        critic_exp_mvg_avg = torch.zeros(1)\n",
    "        critic_loss_criterion = torch.nn.MSELoss()        \n",
    "        \n",
    "        if USE_CUDA: \n",
    "            critic_exp_mvg_avg = critic_exp_mvg_avg.cuda()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_id, sample_batch in enumerate(self.train_loader):\n",
    "                self.model.train()\n",
    "                \n",
    "                self.scheduler_actor.step()\n",
    "                self.scheduler_critic.step()\n",
    "                \n",
    "                inputs = Variable(sample_batch)\n",
    "                \n",
    "                if USE_CUDA:\n",
    "                    inputs = inputs.cuda()\n",
    "\n",
    "                #Model is combinatorial\n",
    "                R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "\n",
    "                if batch_id == 0:\n",
    "                    critic_exp_mvg_avg = R.mean()\n",
    "                else:\n",
    "                    critic_exp_mvg_avg = (critic_exp_mvg_avg * beta) + ((1. - beta) * R.mean())\n",
    "\n",
    "                #Vector of length equal to the mini-batch size: Q(s,a) - V(s)\n",
    "                #advantage = R - critic_exp_mvg_avg                \n",
    "                advantage = R.unsqueeze(1) - values\n",
    "                \n",
    "                #print (\"Advantage function: \", R.mean() - values.mean())\n",
    "\n",
    "                logprobs = 0\n",
    "                for prob in probs: \n",
    "                    logprob = torch.log(prob)\n",
    "                    logprobs += logprob\n",
    "                    \n",
    "                #logprobs[logprobs < -1000] = 0. #Works with PyTorch 2.0\n",
    "                                \n",
    "                #For Pytorch 3.0                                \n",
    "                if logprobs.data[0] < -1000:\n",
    "                    print (logprobs.data[0])\n",
    "                    logprobs = Variable(torch.FloatTensor([0.]), requires_grad=True)\n",
    "\n",
    "                reinforce = advantage * logprobs\n",
    "                actor_loss = reinforce.mean()\n",
    "\n",
    "                self.actor_optim.zero_grad()                \n",
    "                actor_loss.backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm(self.model.actor.parameters(),\n",
    "                                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.actor_optim.step()\n",
    "                \n",
    "                #Do critic gradient descent\n",
    "                self.critic_optim.zero_grad()\n",
    "                loss_critic = critic_loss_criterion(values, R.unsqueeze(1))\n",
    "                loss_critic.backward()\n",
    "                torch.nn.utils.clip_grad_norm(self.model.critic.parameters(),\n",
    "                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.critic_optim.step()\n",
    "                #print (\"Critic's loss: \", loss_critic.data[0])\n",
    "                \n",
    "                #critic_exp_mvg_avg = critic_exp_mvg_avg.detach()\n",
    "\n",
    "                self.train_tour.append(R.mean().data[0])\n",
    "\n",
    "                if batch_id % 100 == 0:\n",
    "                    self.plot(self.epochs)\n",
    "                    #print (\"Epoch {}, Batch {}: Tour length {}\".format(epoch, batch_id, R.mean().data[0]) )\n",
    "\n",
    "#                 if batch_id % 100 == 0:    \n",
    "\n",
    "#                     self.model.eval()\n",
    "#                     for val_batch in self.val_loader:\n",
    "#                         inputs = Variable(val_batch)\n",
    "                        \n",
    "#                         if USE_CUDA:\n",
    "#                             inputs = inputs.cuda()\n",
    "\n",
    "#                         R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "#                         self.val_tour.append(R.mean().data[0])\n",
    "\n",
    "            if self.threshold and self.train_tour[-1] < self.threshold:\n",
    "                print \"EARLY STOPPAGE!\"\n",
    "                break\n",
    "                \n",
    "            self.epochs += 1\n",
    "                \n",
    "    def plot(self, epoch):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train tour length: epoch %s reward %s' % (epoch, self.train_tour[-1] if len(self.train_tour) else 'collecting'))\n",
    "        plt.plot(self.train_tour)\n",
    "        plt.grid()\n",
    "#         plt.subplot(132)\n",
    "#         plt.title('val tour length: epoch %s reward %s' % (epoch, self.val_tour[-1] if len(self.val_tour) else 'collecting'))\n",
    "#         plt.plot(self.val_tour)\n",
    "#         plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_train = TrainModel(tsp_20_model, \n",
    "                        train_20_dataset, \n",
    "                        val_20_dataset, \n",
    "                        threshold=3.99)\n",
    "\n",
    "tsp_5_train = TrainModel(tsp_5_model, study_dataset,\n",
    "                        study_dataset, threshold=3.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAE/CAYAAAC9y4P/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXecFdX5/98Pu0tfOixVFqQXAV0RFHQVRBQjGhu2qNGgUWOMSQzGElv8kvKL0RhFYjf2XlAUgQUiHUV6Z+m971K2nd8fM3f39r393p37vH2tzJxz5swzZ+Z+5sxzmhhjUBRFUZxFrWQboCiKosQeFXdFURQHouKuKIriQFTcFUVRHIiKu6IoigNRcVcURXEgKu5+EJEJIvJQsu0IBRHJF5GtSTr3IyLy32ScOxKSWVbJJF2vO91xnLiLSKGIDI8mD2PM7caYxyM8f4GI3BrN+VORdBQIEblKRGaLyFERKUi2PfFARE4SkSKvPyMivw2QvomIvCYiu+2/R7zizxSR+SJyRESWiMgQt7g2IvKZiGy3z5HrdWw7EflURPaLyFYRud0rPkNEnrCPPyIiP4hIEzuuj4h8LSJ7RcRn8I6INBORj0WkWEQ2ici1XvHX2uHFIvKJiDSzw+uIyEt23BERWSwiF7od10tEForIAfvvWxHp5Rb/iIiUepVv52pvTAxwnLhXh4hkJtuGSKnJttdQ9gP/BMaHe2Cy7lW45zXGbDbGNHT9AX2BCuDDAIc8BdQHcoGBwA0icrN97mbA58DfgCbAX4HPRaSpfWwFMBm4PEDe/wU2AjnAKOBJETnXLf5R4ExgMNAIuAE4bseVAu8BtwTI+99AiZ33dcDzItLbtrs38IKdXw5wFHjOPi4T2AKcAzQGHgTec3sxbQeuAJoBLYDPgHe8zv2uexkbYzYEsDG2GGMc8we8gfUAHQOKgPuwHkKDddM3AzPttO8DO4FDwEygt1s+rwJP2Nv5wFbgt8BuYAdwc4Dz/xkox3rgioBn7fAzgQX2uRYAZ7odUwgMd9t/BPivve3Xdq9z5gNb3fbbYv0w92D9UO72yvs94HXgCLAcyHOLPxX4wY57H3gXeAJoYJdphX1dRfZ5guYXwv3qAUzBEtHVwFVe92CCHX8EmAF0dIsPVqbNgFewfngHgE/CvZdedt4KFFSTxpX3H+zn6g07/GJgMXAQmA2cYoffDHzudvxa4H23/S1Af3v7aXv/MLAIGOp1Tz/AEsbDtq317PI7AKwAfu/+jFRzHX8CpgeJ3wuc7rb/R2CW27Uu90q/BrjFKywT67nOdQtraIe1dAub6FaOTe3n7uRq7O8CGK+wBljC3s1LK8bb208Cb7nFnWynzw5wjiXA5X7CM4E7gaP+fs+J/nNUzd0YcwOWCP7EWG/Iv7pFnwP0BC6w978CugKtgO+BN4Nk3Rrrrd0OS2j/7VYbcT//A8As4C77/HfZtZlJwDNAc+AfwCQRaR7GpXnb7hcRqYVVc/rRtnUYcI+IuB93CVbNoglWLeNZ+9jawMdYotAMeBu4zL6uYuBCYLupqn1sD5afnedzIuKqAXnb2gBLuN/CugdjgOfcP2mxaliPY9WIFmPfoxDK9A2s2mVvO++n3PIM6V5GSGussusIjBWRAcDLwG22nS8An4lIHayX1VARqSUibYHaWDVS7M/2hlgiAtbLq7+d91vA+yJS1+28o7EEvglWGf0JS6BOxnpmbgzFeBER4GfAa9Ul9druEyDOX3x1eQbKuy9QBlwhIjtFZI2I3BlCvgDdgDJjzBq3sB+xng/sf390RRhj1mO/DHyMFMmxw5d7hR/EqtT9C+tl4c5PbFfTchH5ZYg2R08y3ijx/MO3JpyLVSPoHOSYJnaaxvb+q3jW3I8BmW7pdwODAuRVANzqtn8DMN8rzRzgpgD2PoJvzT2Y7fnYtTLgDGCzV/z9wCtueX/rFtcLOGZvnw1sA8Qt/n9e5bDVK++A+YVwn67GrvG5hb0A/MntHrzjFtcQ66uoQ7AyBdpgfWE0DVBWId9LtzSh1txLgLpuYc8Dj3ulWw2cY29vwfpaGoNVS52P9TVzM/BZkHMdAPq53YOZXvEbgJFu+2O9712AfIdi1Y4bBknzX+AjIBurlrweOGHHNcf6QrkGyMJ6qVQAL3jl4VNzd3ve/gXUtctlP7DajrvWPuYlrC+TU7C+Ts/3ysNfzX0osNMr7BeuewpMBW73it8G5HuFZQHfel+PW3wD4A5glNdvoi2QgfW1uQO4JpTfSLR/jqq5V8MW14bdMDNeRNaLyGEsgQWrhuiPfcaYMrf9o1hiEwptgU1eYZuwao6hsqX6JIBVY2wrIgddf1ifzTluaXa6bR8F6tp+2rbANmM/kWGcN1B+odh6hpet12HVfn3Ob4wpwvqxtyV4mXYA9htjDgQ4bzT3sjr2GGOOu+13BH7rdY0dsOwHq/aej/VinYFVMTjH/pvhykREficiK0XkkJ1HYzyfVe/71NYrzLusAnEj8KFd1oG4G+sFuRb4FOsLbyuAMWYf1lfEvcAuYCSWGIbaEH8d0Mm2/XmsF4nr2GP2v48ZY44ZY5ZgfTFeFEK+RVg+encaYbn7Qol3fRW/gfUCv8vfSYz1hTsBeF1EWtlhK4wx240x5caY2VgutitCsDlqnCjugaa5dA+/FushHI71Q8m1w70/KWNx/u1YP3J3TsKqGQAUY7kQXLTGl1Cn7twCbDTGNHH7yzbGhPID2AG0sz/NXXSIwIZQ2QLM8LK1oTHG/bO18vwi0hDLLbGd4GW6BWjm6kWRYLzLaAvwZ69rrG+MeduOd4n7UHt7Bl7iLiJDsdqOrsL6GmmC1c7gfp+8z7sDz3t3UnWGi0g94EqqcckYY/YbY64zxrQ2xvTG0pD5bvEzjDGnG2OaYX1h9XCPrybvTcaYi40xLY0xZ2C9wFzHulxU7tca6jO5BsgUka5uYf2ocq0st/eBSrdYHfs4l7vqJaxK0uXGmNIg56qF9XsOVHkzxEZnqsWJ4r4LqK6rUTZwAtiHdSO8fWSxPP+XQDe7q1WmiFyN9an2hR2/GBgjIlkikkd0b/X5wBER+YOI1LO/UPqIyOkhHDsHy+1xl23naKzeEO7X1VxEGkdhnztfYJXLDfa1Z4nI6SLS0y3NRSIyxG4PeByYa4zZQpAyNcbswGpPeU5Emtr5nh2JgXb51cVyI9QSkboikhVGFv8BbheRM8SigYiMEpFsO34GcC5QzxizFau9ZiSWe+MHO002lq95D5ZAPYxvLdOb94D77etvD/wqBFsvw3L3TA+WSEROFpHmdtlciOXyecItfoBd5o2AvwNbjDFfu8XXxRJOgDrubQci0lNEskWktohcD4zAak/BWH7wWcADYnVP7InlzvrCPlbsvGq7zmO3bbhq1B8Bj9n34Cysyt0b9qnfxPKLD7Xbgh4DPjLGuGruz2O1ef3EGOP6gnDZfL59zRn2Nf/DLseVdvxo+z6IiAzE+vL5NFgZx4xE+H4S+Yd10zZj+f5+R5Xf2t3P2tAu4CNYn6w/s9N0seNfJbivuRA3P7lX3GCsN/4B4Bk7bAhWL4dD9r9D3NJ3BuZhfRq6Ggm9fe6ZQa7Xwz6sT/K3sdwlB4C5Llvxarn3zh/Iw3rZFGH1lvkIeMgt/ctYL8SDVPWWCZbfBGBCENu729e8x853GlU9RF6lqrdMEVaPpk5uxwYr02ZYNdBddhl8FOG9vMm+Hve/V0O5D27hI7EaRA9i1ajfx60Xhh32itv+QuArt/0Mu9wP22nvc7fZ+x7YYfWxejAdJMTeMsDXeLUP2OFDgSK3/auwvpyO2s/KBV7p37bvySGs3latvOK9y9O4xd1jPwvFWP73PK9j22F1pSzCale4zc+z5/5X6PVMfGLnvRm41ivva+3wYixtaGaHd7TzcvWAc/1dZ8dfCayyw/ZgPc+neJXHPjt+FW691+L9J7YBiuKDiMzDEudXknDuV7EE6cFEn1tRnIAT3TJKhIjIOSLS2nZ13IjVI2Fysu1SFCV8dMSj4k53LH9tA6zP3iuM5cNWFKWGoW4ZRVEUB6JuGUVRFAei4q4oiuJAUs7n3qJFC5ObmxvRscXFxTRo0CC2BtVgtDw80fLwRMujippUFosWLdprjGlZXbqUE/fc3FwWLlwY0bEFBQXk5+fH1qAajJaHJ1oenmh5VFGTykJEQppOQt0yiqIoDkTFXVEUxYGouCuKojgQFXdFURQHouKuKIriQFTcFUVRHIiKu6IoigNRcVcURXEgKu6KoigORMVdAeB/a/dSXqEzhCqKU1BxV5i1dg/XvzSP56avS7YpiqLECBX3NOaTH7axZf9Rdh0+AcDGfcVJtkhRlFih4h4BOw8d50RZebLNiJp73l3MZc/NRhdsURTnoeIeJhUVhkH/N5Vfv7042abEhL1FJyq3BUmiJYqixBIV9zBx1XG/WbEzqXbEEq23K4rzUHEPgwWF+1m980iyzYgJsXDFzN2wj+cL1sfAGkVRYk3KLdaRalRUGPYUnSCnUV2unDCnKlyru4yZOBeA9XuKeGx0b+rX1sdJUVIFR9bctx08xuc/bo9JXs/PWM8ZT06lcK9vT5JHP1/OnPX7Is7739PXMX31bp/wJVsP8uXSHRHnGwoeFXd7W0J0uRtjPGr+HyzayvsLt8bOOEVRosaR4n7Zv7/jV2//EFLaPUdO8M78zQHj//b1agC2HzrmE/fKd4Vc85+5kRlp533zKwt8wi959jvuePP7iPMNRnmF4bXZhZSUV/jEiVe6HzYf8NsrqNP9X3L7fxd5HqttsYqSUjjyO3r3kRPVJ7IZ+8ZCfth8kCFdW9C+af2oz328tJzMWkJmRmzfm2t2HaF903rMWruXU09qSpP6WazbXUTPNo1CzmNv0Qlen13IM9PWceR4aWX4niLf8np22jqe+nYNAIXjR/nEf718l8e+9qZUlNTCkTV3F96NhkUnynhtdiHGGNbtPsLDny6r7Ar445ZDGGOYs34fI/85k6krd3llFvg8S7YepOhEGQA9HprMmIlzOXS01CPN9FW7OV5q1YI//mErlzz7P4/4A8UllfHenCgrZ8RTM7n5lQXc9sYibnhpHn/5ahUXPj2LDXuKOF5azqJNB5i0ZAe3veG5uPjBoyWc9vgUFm85SN4T3/LMNGsU6uHjZZVpXF8nS7Yeqgxbuu0QiqLUXBxZc3dhTJW74PvNB/jFawvZV1xCx+b1ucnLHXLnW9/z5GV9+ePHSwG45bWFfmus/rjk2e+Aqhruwk0H6PfYN5X7Xf74JWUVhusHncQTl/blN+/+6JPHgMenALDoweGVYcdLy6mblUFZufVmmbdxPwCb9x/l+80HANhfXMKEGet5z8vnfehoKUUlhnkb97OvuIRnp1U/tUCFP0e8nVfj+llBjy314+ZRFCV5OLrmPvwfMyr96T99bjb7iksAOF7qX4hW7zzssT95WVWj5qb9R8M+/5vzNgFQZnet2bTPfx7ujb+3vVHly+718GTA96PBmKowEWHZtsN40++xb7hr2lEy7Leb91fMxJkbfI6p5eY4/3ZlVUNvv8e+4YNFwRtMDx8rDRqvKEpicbS4b9hbzLiPlvLKdxsjOv4FNwG8/6OlYR//wMfLPPbLKwzfrdvrk8698XfhpgOV2xUGfth8oLKnTi1bew2m0sctAit2+Iq7C5deV4TgFA/WKDpr7R4ANvrpNWTZpChKKuE4t8zjX6zwCXv0c9+wUIhFI6F7jXn2+n3MDrPr5GXPza7cdvWtP15aweItBwGqnTDgltcsH7yrTSAYq3Ye4R9T1nDv+d0Cpjn37wV+w0N5eSiKkjgcV3N/6X/V19Lj1W3PuxEV4j/Y6a63QuvyuaDwQPWJgGemruXwcd/r+Hq5c6ZbUJR0wHHiHgqHAviHvXX4WEl4Mz/+5j3fycTiXaPddtC3/320fLnEdwDV8dIK1u0uCniMVtwVJbVIS3G/74MlIaVbvSu8eWQ2+2l0de9emCgCdakMFVevHG92HT4eVb6KoiQOR4n7d9ui67Hx+pxNUR3vr2Z7+fOz/aSMLz0emhzV8R//sM1v+F1vBR41W1KmXSEVJZVwlLj/Z2lJsk1wNAf8tCm4eDGEtg5FURJHteIuIi+LyG4RWeYW1kxEpojIWvvfpgGOLReRxfbfZ7E0XFEURQlMKDX3V4GRXmHjgKnGmK7AVHvfH8eMMf3tv0siN1NRFEUJh2rF3RgzE/BuYRsNvGZvvwZcGmO7lBqITkGgKKlDpD73HGOMq7/cTiAnQLq6IrJQROaKiL4AHE68pilWFCV8oh6haowxIhKol3NHY8w2EekMTBORpcYYn3XZRGQsMBYgJyeHgoKCaM1SksCUFbt47bOpdGyUkWxT/FJUVKTPlhtaHlU4sSwiFfddItLGGLNDRNoAvssJAcaYbfa/G0SkABgA+Ii7MWYiMBEgLy/P5Ofnh23QgsL9wJxq0ynx5U+zj7Pq8ZHUzUo9gS8oKCCSZ8upaHlU4cSyiNQt8xlwo719I/CpdwIRaSoideztFsBZQGSTvITAwSDd9JTEUnyijD9PWhH2CF9FUWJHKF0h38aqEncXka0icgswHjhfRNYCw+19RCRPRF60D+0JLBSRH4HpwHhjTNzEPZq1TJXY8ursQv4za6PfaYUVRUkM1bpljDHXBIga5iftQuBWe3s20Dcq68Jgy4Hw51tX4oNrtGp5hfaeUZRk4ZgRqhm6QnPKUNm6rvdEUZKGY8T9eJn6dxVFUVw4Rtx1AE3q4PK1Pze9+nVbFUWJD44Rd3Xvph5l8V6pRFGUgDhH3HW1CEVRlEpU3BVFURyIg8Q92RYoiqKkDo4R93JVd0VRlEocI+5G3TIpSbTruSqKEhmOEfcerRsl2wTFD1NW7Eq2CYqSljhG3McM7JBsExQ/6PeUoiQHx4i76FB3RVGUShwj7upzT03U564oycE54l5N/LAerRJih+LJfR8sAWDZtkOs3nkkydYoSvrgHHGvRt3P6tIiIXakmnfoz5f1SbYJAFz8r/9xwT9nJtsMRUkbHCPunVo08AkbdUobAO49vxvZdUNfUfD3F3SP2I6Ozer7DX/lptMjztOd/h2ahJz21ZENuO6MjpX7d53bJaTjBnduHrZdiqKkFo4R92YNavuE/fvaUykcP4q7h3UNKY/aGVZx3DKkE33ahd618seHR1Rud8vJ9psm1+3ls/jh8yu3fzG0U8jnGdq1BX+74hSG98wJ+Rh3fnN+t5DSZdRKsc8PRVHCxjHiDvBUfr2wj+nROpvC8aMoHD+KkX1aA5AZprjVrV1VjOeG4NtvUr/qRdS/Q1MKx4+q3G/XJPA1dM/JpmtONi/emBeWfS68Lyu3ue9XRuH4UfxhZA9Obun7JeTO2d1a0qZxXWbdd25EtiiKEl8cJe5N69bioYt7+Y0LpS/N36/sx/w/DiMzo6pYPr7jzIDpG9fL4pxuLamTmVEZNsTNt//2LwYFPPZC+0XiTe1M/7dkUOdm/OLszgHzC2anC+/uolec1t5vur7tGzP1t/lB8/rJKW2Yc/8w2jcN/4WqKEr8cZS4g+VS8Ue9LEuArwwgaGAJa6tGdYGqBtrMWoGL6Mc/jeC1nw/0CHPpZ3bdTAaf3Nxv7TgY5/fydbn0aJ3NO2MHk2PbBr41/AEnNWXchT0A+OiOM1nwwPDKuOvOOMknz1WPj+TOanzwwXzvrheFji9QlNTEceIeiIv6tuH+C3vw6OjeHuF3BBA4l7i7a1d+95bVnqd5gzoA3DokcC0boEurhgC0aOjZVtCjdTY9Wvv327tTJ8v31t12dmcWPTicU09qSsvsOpXhT1zah/VPXuSRtm5WRrXC/PbYQXzxqyHV2lIdk5ftjDoPRVHCI23EPaOWcNs5J1O/tmevmUv6tfWb/uf2F0CHplU171dvHsjCB4f7Te+iXu0MNv7fRdw9zHppDOzUDICGdTzP++thXXnr1jM4w64du3roXDagHe/fPpiZv6/yZfvr5nled1/fvojQvGEdv+GRNpL2adeYRnZPo6eu7leVZxh5/HXyqojOrShK5KSNuPvjMa9avDtXnNaewvGjaFw/yyO8hR/x9EZEKmvFj1/ahym/OdujJg2QmVGLM93883ee24XC8aMQEbLrZnFS8/pcNqAd4L+R9p7zuzE2iA8+HpzXPYfbzzkZgCZe5RKMbQePxcskRVECEHrn7xrE/D8O41gIw967B+i2GEvqZGbQNcLzPHV1f+6/qEelq8edhnUyuf/CHpWLUceTPu0aM3v9PjIzhHvP70bPNtmcF8aI3xNlusCtoiQaR4p7K7eGx2DEcjaaL+8eGpcaaqvs0K4lnrxww2ms3nmEBrZraXT/dkm2SKmJrN11hIZ1M2nTWHtYJQJHinu8Gdq1BRfbo19d9GrbiF5tgw98OvPk5sxevy9mdsSip8rU355DwzqZnPHk1IBpsutmkZfbLOpzKenN+U9Z00+4j+tQ4kdaivvYszszceaGkPznLtz7pb9xyxkRnfetIP3ek8XJLRsm2wRFUeJAWor7fRd0Z3T/tpXdEatj7Z8vJEP7cyuKUoNIy94ymRm16N22ccjpszJqUSuF51v5+Vmhz0/TpnHyffhK+jFhxvpkm5B2VFtzF5GXgYuB3caYPnZYM+BdIBcoBK4yxhzwc+yNwIP27hPGmNdiY7biIlz/5cz7zqXCT8f5f17dnz7tQn/hKUo4jP9KxzokmlBq7q8CI73CxgFTjTFdgan2vgf2C+BPwBnAQOBPItI0KmuVqMnKqOUxF46LSwe0C9lNpShK6lOtuBtjZgL7vYJHA65a+GvApX4OvQCYYozZb9fqp+D7klAcgjZJKKGSO24Sf/96dbLNcDyR+txzjDE77O2dgL8JxtsBW9z2t9phisP49M6z+OiX1c9KqSgunlcffNyJureMMcaISFTjgURkLDAWICcnh4KCgojyKSoqivhYJ5Lo8hiZm8nkwrKgaZJ5f/T58CSZ5VFeYVLqXjjx2YhU3HeJSBtjzA4RaQPs9pNmG5Dvtt8eKPCXmTFmIjARIC8vz+Tn5/tLVi0FBQVEeqwTSXR55Odbn9zB0+QnxBZ/6PPhSULLY7Lvc5FK98KJz0akbpnPgBvt7RuBT/2k+RoYISJN7YbUEXaYoihpRN9H9GefDKoVdxF5G5gDdBeRrSJyCzAeOF9E1gLD7X1EJE9EXgQwxuwHHgcW2H+P2WGKg+mqPW4UL44cD+6qU+JDtW4ZY8w1AaKG+Um7ELjVbf9l4OWIrVNqHAM7NWPt7qJkm6EoaU9ajlBV4scvhiZ2jnlFUfyj4q7ElNwWDZJtgpJCHDxakmwT0hYVd0VR4kZ5RSxXTVDCIS1nhVQUJf6M/2qVThiWRLTmrsSccRf2SLYJSgqgwp5cVNyVmHP7OSfrajuKkmRU3BVFURyIiruSUE6UlSfbBEVJC1TclYTiZ50QRVHigIq7klD8rQKlKErsUXFXEopqu+Ji5Y7DyTbB0ai4KwlFa+6Ki7ve+j7ZJjgaFXclbvz18lN8wlTaFRfr9xQn2wRHo+KuxI0r89r7hGnFXVESg4q7EjfEz6rZRtVdURKCiruSUFTbFSUxqLgrCUUbVBUlMai4KwlFpV1REoOKu5JQtOKeHuw8dDzZJqQ9Ku5KQtEG1fTgjjcXJduEtEfFXYkrj17S22NfpT09OFqiE8QlGxV3Ja60yq7jsa8Nqs5nf3EJq3YeSbYZaY+KuxJXvLu6q7Y7n29X7kq2CQoq7kqC0Zq74s7xUnXfxAsVdyWhqLY7m08Xb+O+D5aEnP656eviaE16o+KuKErMGP/VqqDxb916hsf+hr06eVi8UHFXEoq6ZdKXLq0acmaXFh5hXyzZkSRrnI+Ku5JQVNvTl0l3D0m2CWlFVOIuIr8WkWUislxE7vETny8ih0Rksf33cDTnU2oe3mKuNff0pU5mRrJNSCsyIz1QRPoAvwAGAiXAZBH5whjj3UIyyxhzcRQ2Kg5CpV1REkM0NfeewDxjzFFjTBkwA/hpbMxSnIpW3BXvgW2HjpUmyRJnE424LwOGikhzEakPXAR08JNusIj8KCJfiUhvP/FKGqFzy6Qntw7pVLl9/aCOHnFHjqu4x4OI3TLGmJUi8hfgG6AYWAx4j0j4HuhojCkSkYuAT4Cu3nmJyFhgLEBOTg4FBQUR2VRUVBTxsU4kFcpj/5EKj/358xewLTs57fipUB6pRDzKY0eA2SAbH9tOQcFuAAoLSzzi5s6dS4t6ye3b4cRnI2JxBzDGvAS8BCAiTwJbveIPu21/KSLPiUgLY8xer3QTgYkAeXl5Jj8/PyJ7CgoKiPRYJ5Iq5fHAd5MqtytadCZ/cG5S7EiV8kgV4lIekyf5DR50+qmcntsMgKXla2Htmqq4QYNo37R+bO0IEyc+G9H2lmll/3sSlr/9La/41mIvpCkiA+3z7YvmnErNZn7hgWSboCQBl7CD73xDQ/4ynbkbVBZiTVQ1d+BDEWkOlAJ3GmMOisjtAMaYCcAVwC9FpAw4Bowx6nRNa7QrpHMJ9NP+1zUDPPb9LZz+4qwNDOrcPC52pSvRumWG+gmb4Lb9LPBsNOdQnIW+253LvI37/YaP6J1T7bE6RXDs0RGqSkLZflCXX3MqRcfLIj5212F9LmKNirsSdx6+uFfl9uItB5NoiRJP/HhbrHCk2nSl5fpFF2tU3JW4UztTHzOnMn3Vbno/PJniE2Ws213kN423mPdq0ygBlin6q1PizlV5HWhUN9q2eyUV+dvXqykuKee5gnX8X4Dpfr0r6vndW8XfMEXFXYk/tTNr8bsLuifbDCUGrNxxmB82V3VndTlT/j19fXIMUgKi4q4oSshc+PQsLntudljH+Ov6ePmp7WNlkhIAFXclIQRoa1NqKJ//uJ3ccZNYueNwtWn93fv87i1jb5TigYq7khgCdaVQaiS/evuHkNP6u/UX9W0TQ2sUf6i4K4oSF1o3qhswLqOWr+IXn4i8n7zii4q7khC03p5+3D2sK4XjR/n1ufvjhRnaKBtLVNwVRUkJnpnmvYibEg0q7oqixAWjiyomFRV3JSGc0r4xAAM7NasmpaIosUAPnK3UAAAgAElEQVTFXUkIHZs1AGBk79ZJtkRJFDoBaHJRcVcSiv7e0we918lFxV1JDHaHCZ3PPY3Qe51UVNyVhKBjmGo+D36yNO7nOF5aHvdzpAsq7kpCUG2v+fx37ubwDojgjd7joclhH6P4R8VdSSj6pZ4+XHmaTg6WTFTclYTgGqU4c+2eJFuiJIq6WRnJNiGtUXFXEoLrA33W2r1JtUNJHcae3TnZJjgaFXcl4by3cEuyTVBSgD+M7MEFvXP8xi3bdohPF29LsEXOQsVdSQjubWv3fbAkeYYoCeG92wZXmyajltA9J9tv3MX/+h+/fmdxrM1KK1TclYQg2l+mRhPu+IRQp5loFWRaYCU6VNyVpNDtwa9YULg/2WYoIfL6nE1xyTfTz7zuOtAtNqi4KwnBu8tzSVkFEwp0/u6awsSZG+KSr7+u8CXlFZXbKvSRo+KuKEq1bDt4LC75+nPX/f3r1XE5V7qh4q4oStLwV3P/z6yNldtacY+cqMRdRH4tIstEZLmI3OMnXkTkGRFZJyJLROTUaM6n1Fx0bpmaS7iukWsGnhRyWp3fP35ELO4i0gf4BTAQ6AdcLCJdvJJdCHS1/8YCz0d6PqVm4+/zWytlNYNL//1dWOl/M7xryGk7Nm8QNF6fkciJpubeE5hnjDlqjCkDZgA/9UozGnjdWMwFmohImyjOqdRQ/NXcp63anXhDlLD5ceuhsNKH272xX4cmAePenh/mZGVKJdGI+zJgqIg0F5H6wEVAB6807QD34Yhb7TBFURQAHr2kd8C4dbuLEmiJs8iM9EBjzEoR+QvwDVAMLAYimoxZRMZiuW3IycmhoKAgIpuKiooiPtaJpFJ5lFf4/8BOpH2pVB6pQLzKI9w8txypCBi3detWCgriP9mcE5+NiMUdwBjzEvASgIg8iVUzd2cbnrX59naYdz4TgYkAeXl5Jj8/PyJ7CgoKiPRYJ5JK5VFeYeCbL33CE2lfKpVHKlBdeUyvdJstCCvfSMr4oe8m+Q1v1DyH/Pz+YecXjGMl5fzps2WMu7AnzRrUBpz5bETbW6aV/e9JWP72t7ySfAb8zO41Mwg4ZIzZEc05FUVJDDe/uoCbXw1P2GPNRz/EfvKwD7/fynsLt/L3b5zdnz6qmjvwoYg0B0qBO40xB0XkdgBjzATgSyxf/DrgKHBzlOdTaijaE9LZtMyuw+9HdKdDs/rJNqVapHI93+TaEW+idcsM9RM2wW3bAHdGcw7FGWg/d2fTo3U2V53u3Z8iNXF1y3X61AY6QlVRlKjJ8DMBWKriMvWdBc5eV0DFXUkIolX3GsOiTQfYc+REWMdkRHl/f3t+t4BxJWWBe9NEQro8itH63BVFcRiXPz+b1mEORIr25Z3bIvBI1S+WbOenp8Zuse1jJRH12K5xaM1dURQfdh4+Hlb6jCiVJJhbJ9AYiUh55PMVMc0vVVFxVxQlaqL1uWdF+3ZQfNASVZJKrP2pSnK4qG90U0YF0/bff7CEg0dLoso/HVGfu5JUFm06wOCTmyfbDCVC5v9xGM0b1om65t6nXeOg8TPX7uWSfm2jOgekV2VCxV1JKunSc6GmEG7f71gtcN0qO3g+seqTfvBY+nwBqFtGSSq1VN1TBmMMXy3bGTTN+b1yWP7oBQmyKPb4W1fAqWjNXUkqqu2pw4ffb+N37/8YNM1/fpaXIGs8idVg0nR63rTmriQV129t64Gj/OOb1ZWf34eOlSbPqDRlV5jdHxPJcwXrYpJPGmm7iruSOC4b4LtOi2vwyx1vfs8z09axZlcRXy7dQb9Hv+GHzQcSbaKSoqzZFZtFO9JppLSKu5JUXL+1E6VWLwaD4bt1ewFYti285d2U6Pjf2r3JNiHuLN+ePs+UiruSMGr76cz82eLtgCXqLiqnZE2IVYqLORv2JduEuLPrcHhz5tRkVNyVhPHHi3py29mdPcKmrtrlsS/2f+D8+bZThRdmrOf9hc6eITEd0d4ySsJoXD+L+y/qyYodh5lluwBcXSFVyJPH/321KuxjfjeiG91ysmNqR592jVi27XDA+LwnpvDKTQPp2z74gKdgpNMgJq25Kwmnaf3aldvaz71mctd5XRnRu3VM8xzcOfhI5b1FJTz+RXSTfr3y3caojq9JqLgrScWl7e4aX7UMWvjV+W0Hj5E7bhLfrthVfWKF46WhT3/bvmm9OFoCJ7dsWG2a1buORHWOA2k0R42Ku5JU/LllXp+zKeL8lmw5CMAHi7ZGZVe68NL/Qq/JtsyuE0dL4OoQlumLdvyDumUUJY64zzHl7ZRxr8G79H7Rpv28OS88wTfa1yYkVu4I7OP2Jt7tIonog37cS9zDuf6ahoq7knAeGNWrcruy5u4n3aZ9RwG4/Pk5PPDxskSYlnZ8sWRHyGkT8bqMRt8/+WEb/54efCRrhdfCH2uidPOkMiruSsJx/7wvq/CsSbn/tl+dXegRF+sVeZTQOa9HK8b/tG/cz9O2ceR+/XveXczfvl4dNE1ZGj1DKu5KUlm/p9hjP9hPb9baPdXmp51vgvP5j9vJHTeJ4hNlYR338k2n07NNozhZVcX7tw8GPF138cTJ0xGouCs1hmmrdifbhBrP01PXAjBlxS5mbw9P4BNB2yb1ePbaAXx77zkR5/HN8sDTFnsvKuJcaVdxV1KMYPPJhPNJvWX/sViY45djJeW8OGuDj/+2JnHPu4uZuCQ1h+JffEpbOofQLTIQY99YFDCuU4sGHvtOXr5PxV1JCVx92u99z3M+8aMlVbXL8vLQxXRFHHtB/O3r1TwxaSWTlobeGKnEjmi6Q+465DmtsZN98CruSkrg7Xt38au3fqjcLq0IpY9y/D+0Dx+3xOVYGAOAUgUnNEo//e1aysormL9xf9jXc8SrrcEJ5REIFXclpdlTVOU6OHqi5olpqrFxr/+XaCryi6Gd/IaXllfw63cXc9ULc/jDh0tCzm/L/qOxMq1GoOKupDTuA2cmB2koSwrOrfSlBO7jIdx5Y+4mJtn98z9dvC3k/Ib+dbpPWJ92kU9ClupEJe4i8hsRWS4iy0TkbRGp6xV/k4jsEZHF9t+t0ZmrpBs60lQJhUgbt508cV3E4i4i7YC7gTxjTB8gAxjjJ+m7xpj+9t+LkZ5PSU+85wLJHTeJe99dnCRraibzNuxztG8ZfBtZO98/KUmWpA7RumUygXoikgnUB7ZHb5KiVOFv7cyPftjGywEmvJq8LP49WGpSXW/uhn1cPXEuf/hwSUSzbKY6pXYPKu8rc/i7LCQiXqzDGLNNRP4ObAaOAd8YY77xk/RyETkbWAP8xhjjs+SLiIwFxgLk5ORQUFAQkU1FRUURH+tEUrk8Lu+axYdrrdpWJDY+9sUKOpf5Tib2yeKqBkPvfGNVHjt3Wo28q1avoqB4fdT5xZNvN1ll/MGirQxruj+sY+tlwjG7c0mqPkdg2XakxFfNQ7F58eIfOLopI6V/K5ESsbiLSFNgNNAJOAi8LyLXG2P+65bsc+BtY8wJEbkNeA04zzsvY8xEYCJAXl6eyc/Pj8imgoICIj3WiaRyebTvdYQP/zETwLJxcvif0b1PG+w7Da1bPt7XHqvymLTnR9i2lR7de5AfwjS1yaTwu42w0lrgol6H3sCCkI6789yT+f0FPcgdZ5Vn0p6jEJ6LjVkdGTmgNUyb5hHuY7OfvPr3H8DATs1S+rcSKdG4ZYYDG40xe4wxpcBHwJnuCYwx+4wxrr5sLwKnRXE+xUHEwkNw2xsLo88kjXjo09Bn1vz9BT3iaElsefTzFTxjT6sQLk50VbmIRtw3A4NEpL5Ys+8MA1a6JxCRNm67l3jHK+lLLH5S+4qTO3T8gU+WJvX8oeBezvGckiHZBBoEVx3OlfYoxN0YMw/4APgeWGrnNVFEHhORS+xkd9tdJX/E6llzU5T2Kg4hFhWmWDZsvjVvM5c/PzusY0rDmA4hGZRXGB79PLo1R5PNHy8K7Qti/sbg7QmBlhN8f6FzV+yKqreMMeZPxpgexpg+xpgbjDEnjDEPG2M+s+PvN8b0Nsb0M8aca4wJf5l1xZHEov96LKdr/ePHS1m06UCNmgxs3e4iNu8LPOryRFnNH9E79uyTo87jRFk5PR6a7Dfuw+9V3BUlpsTa1fnugs1BhS5UpqysOQtrD//HDM7+m++oSxcS4bdNi4bxXSs10fxn5oZkm5AUIu4toyjRUBEDdXdJV3mF4Q8fLo2JKD01ZQ0X9G4ddT6hcqKsnPIKQ/3aof0Ut+w/SsvsOtTNyoibTW2bVA00f+Wm09lQg+ajcae0vIKsjFr8/Zs1IR+TO24SPxvckcdG94mjZYlBa+5KUohJzd2rYrq/ODHzk0+N0aIhJWUVDPnLdHo9/HVI6SsqDEP/Op073/w+JucPhHuxntujFbcM8T+BV6oT6URzr88JbzH2VEXFXUk61S1qHIgNdg8JV3e2WLjLQ3np7I9RL51bXlvAniOhv5Bcpk1bHfjl8sacQnLHTYp4EYqbzszl2WtPjejYmsq+otRctCRaVNyVpOAuotUtahyMA8UlMe3OlsiJymat3RtWeleNOtgL6M15mwHYdvAYczaElz/AI5f0pkOz+mEfl5KE2ORw2hPfxteOJKHiriSFWInogMencO1/5sYkL4i8v3QiCFRi7pOCuXoQGQM/f9UZg7yevXZARMftPHSc0vJQFnixqEk9pUJBxV1JCrHsLbOg8EDM8qqJsyf+ZXJVD2NXZfX5gtSe8yYcRvRqzem5TcM+7oJ/zuSBj0MfaPb8DOeUGai4K0mie+vsZJvgGCbO3MBe22/sWjvWSeu71s6sxfu3n1l9Qj9MXRla4/e6g+XMWLMnonOkKiruSlKIZ1c+F+t2F/GW7YN2AsHmQbnhpfnMWusscfJmYG6zsI8J1OW2dqan9D0x9zgnauCauMFQcVccy4VPz+SPHy8Nq0dKLJm+ajed7p9UuaB2LDnilefmfcXsOHQ8qjwb1U3tYS+3BlhTNRgHjvov+2m/Pccn7Meth8LOP5VRcVcci2vul9P/HL/eEMFqy89MW4sxsNbPgiPR0vcRz6UTTOX/wmdo1xa0a1KPp67uH7Vd8SSWS+K1b+qQHkFBSO1XtZK2nNaxKYs2xa6hNF4E6/Meq0bj6at306tNI5o1qB30XJGO+n395wNjOk+Pkykrr2Dn4eM14uWgNXclJRnUOXz/aiyokxn7n0S4urmgcD+54yaxoNCa6fDmVxbw0+eCz1h5rLQ8YreMCnvo/GXyKob8ZTo7o3SBJQIVd0VxIxKdM8bw9vzNAaeVBdh9+Di54yYxPcDUBb/87yJyx03ieGk5V06YA8B7C6pWpNx2sPq52J+OcMGKmoKrh9Xt50Q/U2SkuAaexWqUcjxRcVeUEPnf2r1+BXzqyt3c/9FSj/7mCwr3s3jLwcr9ORv2AXDzq/6Xuftq2U4Aj8bX9xdt5RevO2MgUizo0Kw+heNHJWSum6emBJ9sLJEjmSNFfe5KSnJax/AHrUTClv1HGfrXwNPmuli98wjXvzSPMV5rpv76ncWV2/uKSjh0tBSDqax9h8vAP0/12J+yomoKYgevCBcWPuvmxoGnp67l0gHtWFi4nyvzqu55TXJhqbgrKUmiGqzufW+xx36gOdA377fmil+3O3DPl3W7i+j32Dc+4YKnKJz2+JSkLxHoIhFCGQ9E4v+yG/XMLI6WlHuIe01C3TJKWhBoVaJAYn7oWCm7Dlc1moXiHnGNDvXH8m1VfagjFfaDx2L7Qhh+UiaTfjUkpnkmikR8xRwtCdyGUhO+olTclbSg+4OTmbu9zDciwFf2tf+ZyxlPTvUJXxhh98wXYrAa0OuzYzvP+PW96tCqUd3qEyoxYcv+o+SOm8SSrQerTxwDVNyVtGHCkqqRqt0e/IobX57vo+0u78ny7VYt/HhpOS/OSo1l2p6NcN77dCKSCcbiSVl5BW/MKWTbwWMU2PPwv+vWCyqeqLgraUXuuElUVBhKyiqYsWaPT9fHEb1yWGj3Lwd4dto6npi0MqpzpmKf6J8OaJdsE+LCqL5t4pq/63E5WlJOWQjTCb8+ZxMPfbqcs8ZPq5xrP1EeHRV3JWWZ8ft8AM7p1jKm+Za4/Si9fe5tm9TjCreeLt5zuETCL+O8LF4kDD65ebJNiAtlCZqy+aoX5nD7f6u/r+8v2lq5vWrnESBx/noVdyVl6di8AZPvGcrz18d22beiE3587zbev7ua1PUtFJrUz6JLq4YM75mTbFPigvdsj/Hk25W7qk2zMkgje7xRcVeSxo2DO1abpkfrRtSvHdseu/M3Vrldlm0PPhNgSRgr+dQE/t+V/fj23nNoGmSemprARX1b+w2Px2IrV70wh9xxk4DgPaJcHCguYfxXq0Jy28QTFXclaYxN0jDyO9zcJEeOe9bij3l1f3PSfPBO4p9X+196r7zCxHx+IPfKgDeDnpzKDS/N8wh77IsVTJixPkjNPjF+GRV3JWmkosPj1dmFyTYhrtSE/tmhEMj9cvEpbeO2EMwEP8vw7Tx8nFlr9/Lqdxsrw1xjKpL90afirtRIeugyfRER6bTAqcjPz/KdY6Z147oRTf4WCuO/WhUw7pHPV/gssL2/2P8iMdqgqjieYD/CbK9Vgb741RAeHNUTgLvO7cJvzu8WT9McRbechuR3t3octWtaL8nWxI6Hf9LLYz+7jvXMJOuL8LkCz3EIxQFGuCZK3KNqqRKR3wC3YjmRlgI3G2OOu8XXAV4HTgP2AVcbYwqjOaeSHrRp7ClCfdo1pk+7xgzp2oKurbJD6qmgWNx5bhd+ckpbNu4r5uSWDZNtTtzIaWyNtg21h9MTl/bhwU+Wxez8M9fs5bJT21ebLlELcUdccxeRdsDdQJ4xpg+QAYzxSnYLcMAY0wV4CvhLpOdTnEegeV2C0aN1IzJqRXJk+lJLhFq1xNHCHgnXD+pI4fhRMctvfuF+zho/jS+X7gyabufh4xwKsLZrLInWLZMJ1BORTKA+sN0rfjTwmr39ATBMnNZxWIk5b9wyMNkmOIqRffx3G0w3fpmf2N5ZwRZmL62If2trxOJujNkG/B3YDOwADhljvOc7bQdssdOXAYcAZw6NU8Im0HSzQ7tWPyL1zC4t6N22Ea/93PdF0LaxToblYva488jKcG7TWkYt37pioNrjH0b2iK8xXizdFngMRbC4WBGxz11EmmLVzDsBB4H3ReR6Y8x/I8hrLDAWICcnh4KCgohsKioqivhYJ1ITy6NuBiHb/PtTwGxf7hN+aSfDc4v9HJCGLJo/lzW1/ctdTXw+vPlZzyxeWW5NhVxcXExBQQElpf6nRi4oKOCm3rVpXEcSct3B+se/MuUHZEd859KPpkF1OLDRGLMHQEQ+As4E3MV9G9AB2Gq7bhpjNax6YIyZCEwEyMvLM/n5+REZVFBQQKTHOpEaUR6TJ1Vuju7flqfH+B+cEoyXW+/i569Wzbfev28fWLwoJubVdH4y4tyAcTXi+aiGfODTx6ewv7iEcT/pR37/dtSeNQVKfAU+Pz+ffH+ZuD2DiaJtmzbk558S13NE8722GRgkIvVtP/owwHv6vM+AG+3tK4Bpxjioo60SU/IiXFqvUd0sj319wCw6NHNOt8dgvDt2ENedcRI/OaUtENki54mmcF9x3M8Rjc99HlYj6fdY3SBrARNF5DERucRO9hLQXETWAfcC46K0V3EY7ivZRyrK7j/mZjV8zpRYUtvBvnZ3uuZk8+fL+lLLj/+9Mk2r1OopNHdDYJdNrIjq7htj/mSM6WGM6WOMucEYc8IY87Ax5jM7/rgx5kpjTBdjzEBjTGqseqCkDOMujG0j1/cPnR/T/ALhPcgqFTmpWWLWoU016mT6Tj+Qjl9z6fFqV2oEkX9Nex6ZGaQGFysScY5oSddex/560KQjKu5KyhCr2lWT+lnVJ4qSs2O8gIgSO9rbUyxkZYQm8lecVv2o0ppI6n9bKko1+FZQ419za1Iv/i+QaEnX+utz153K7PX72H7wWOUSic3qB26LaVwD7mUkqLgrSaduVi2Ol1ZELEa92zby2O+SgMazmuDyqAEmxoUm9Wtzkb2W6q1DO/PmvE2M6BV4lK5Ti0ndMkrSmXf/cK4fdBJX5nWI6HjvBrRE1MRaNEzNXjnndGtZ6Za6KsLydBrXndEx4GhogPp1nFnHVXFXkk7j+lk8cWnfuC2yEA/O7NIiqed3TX/szZjTO7D44REUjh/FiN46p0wo3JHgOWcShYq7otRAxgw8ySfs4Yt7caHtjlBCp25WBq3qW86Z341wzjoBKu6KEiFNY9grp3OLBmGl9+6K2atNI34+xHdlIiU8gg2EqmmouCuOZ3T/tjHPU4Cm1YyGDUew/zmmv8d+dTXIulkZfHLnWSHnrwTnl/3qMLJ3azo0TczAr3MS0JVWxV1xBE+P6c99I7tX7rt80qee1CQu5+vZplG1vSz8LWkXqAfLKe2bsOSREZX7d53X1SP+moEduPu8Lh5h/TvE59rSkU6NM5hww2kJGwB101m5cT+HirviCEb3b8cd+VXid+vQzhSOH8VHd8SndhtK4+8AL/Fd+ODwoHOcuGSloVfvjf4dmvB/Pz2Fe0d0x1t7nrysb0j2KumHirvieBLtRf3DyB5cfmp77ji3S/WJg9C5peXWaeO2+Mj03+Xz8k15lfuntG8c1TmU5HBahDOghoMzO3gqSjUM7dqCWWv3RnTs2LM7A4EHMgVbzs199dfambXI79aSS+w2Ae/pF24+qxMPfbLMw7ffsXkDOjYPr/FVCZ1EVQS8p6mOByruStpwQcdMvt5UFnU+d0ZRIz+1Y1NW7zrCpLuHcFKz+mQH+ZGHIjSueVSuG+TbNVJJb9Qto6QNHRuHN0iqcPwov+GuCrtLfF+6Mc9vOn88eklvvvr1UHq3bRxU2CG0idSa1K9N4fhRXHdGx5BtUAJzagLcJYlCxV1JG6pbBOymM3MDxv3rmgGVDZ0uUXeJfPswus/VzqxFzzaNgqaRAP8q8SenUV2WPXpBTPO8OknTQKi4K47Hn2/cXz/jQEP6R/dvy0/6ta325VCtHSHGZ2VaP8srTmvPmNM78LsR3QMfpMQc795K0ZIZ4tTDsUbFXXE8151h+aN7NKtyy/hbpSjTbVm6620fduH4UT6LdrteFm2bWP7uOpm1+O350Q9bz66bxb3nd+O92wYBVnfL8ZefUu1gKSX2LHxweMjzwVdHRZKWgVJxVxxPXm4zCsePonm90B/3YFPEunj66gE8c80Acls04FfDuvpNM7hz88rtRiHMVnn3sK50aZUdsp1KfGjRsA5r/3xRjVhOMRAq7kpaEqgy9cw1Axj/075+V1ryPqZx/Swu6Rd8agPXGrF92zUmK00WrHYSs+47l8dG9/YIG9S5WVh5/P6C7lyVl/jVnvRpUxQ3LunX1u+MiwAul3s4H+su10085rdR4k+T+rXpYLvwLuzTmsLxoxh1Snj3slmD2vz1in7xMC8oNfebQ1ESTP8OTZizYV/A+UcuG9COy0/1rKG1zK7DmicujJn/Vkk8Z3dtyR35J3OLPevmmNM7sL+ohLFnd6bnw5OTbF1gVNyVtOfu87rw9fJd1aab+LPTWL+nOOC8Mk9d3d9veO1M/UCuyWTUEu4b2aNyPyujFr8e7r+NJRgi1tdfqyCrQsUSFXclLXHv1XjviO7cG0J3w+y6WToTo+JB95xsVu864hPer31jzuuRw+HjpZVhDWtncuREGR/+8syE2KbirqQtD47qySC33iyKEi7vjB3EgMenAHB6blMWFB4A4N3bBvt84bnqE41juMhLMFTclbTkjE7NGNlH1xhVosN9DMI7YwezYvth2jet59d116VVQxZvOeizila8UHFX0hIdGKTEmoxaQt8gUzC/ctPpLNt+iPq1EyO72tKjKIqSAJo2qM3QrvFfXs9FxOIuIt1FZLHb32ERuccrTb6IHHJL83D0JiuKoijVEfH3gTFmNdAfQEQygG3Ax36SzjLGXBzpeRRFUZTwiZVbZhiw3hizKUb5KUrcCLaOqaI4hVh59scAbweIGywiPwLbgd8ZY5bH6JyKEjYf3XEmnXSZOiWGdMtpyJpdRck2wweJeo5qkdpYwt3bGLPLK64RUGGMKRKRi4CnjTE+Q7tEZCwwFiAnJ+e0d955JyJbioqKaNhQa2UutDw80fLwRMujimjKorTCUFYB9TIT08Xx3HPPXWSMqXb5r1iI+2jgTmPMiBDSFgJ5xpiAKxPn5eWZhQsXRmRLQUEB+fn5ER3rRLQ8PNHy8ETLo4qaVBYiEpK4x8Lnfg0BXDIi0lrslQ1EZKB9vn0xOKeiKIoShKh87iLSADgfuM0t7HYAY8wE4ArglyJSBhwDxphoPxUURVGUaolK3I0xxUBzr7AJbtvPAs9Gcw5FURQlfHSEqqIoigNRcVcURXEgKu6KoigORMVdURTFgai4K4qiOBAVd0VRFAei4q4oiuJAop5+INaIyB4g0tklWwABpzZIQ7Q8PNHy8ETLo4qaVBYdjTHVrvqRcuIeDSKyMJQ5F9IFLQ9PtDw80fKowolloW4ZRVEUB6LiriiK4kCcJu4Tk21AiqHl4YmWhydaHlU4riwc5XNXFEVRLJxWc1cURVFwkLiLyEgRWS0i60RkXLLtiQci0kFEpovIChFZLiK/tsObicgUEVlr/9vUDhcRecYukyUicqpbXjfa6deKyI3JuqZYICIZIvKDiHxh73cSkXn2db9rLwWJiNSx99fZ8bluedxvh68WkQuScyXRIyJNROQDEVklIitFZHC6Ph8i8hv7d7JMRN4Wkbpp9WwYY2r8H5ABrAc6A7WBH4FeybYrDtfZBjjV3s4G1gC9gL8C4+zwccBf7O2LgK8AAQYB8+zwZsAG+9+m9nbTZF9fFOVyL/AW8IW9/x7WwjAAE4Bf2tt3ABPs7THAu/Z2L/uZqQN0st81eYYAAAMBSURBVJ+ljGRfV4Rl8Rpwq71dG2iSjs8H0A7YCNRzeyZuSqdnwyk194HAOmPMBmNMCfAOMDrJNsUcY8wOY8z39vYRYCXWQzwa60eN/e+l9vZo4HVjMRdoIiJtgAuAKcaY/caYA8AUYGQCLyVmiEh7YBTwor0vwHnAB3YS7/JwldMHwDA7/WjgHWPMCWPMRmAd1jNVoxCRxsDZwEsAxpgSY8xB0vf5yATqiUgmUB/YQRo9G04R93bAFrf9rXaYY7E/GwcA84AcY8wOO2onkGNvByoXJ5XXP4H7gAp7vzlw0BhTZu+7X1vlddvxh+z0TimPTsAe4BXbTfWivRRm2j0fxphtwN+BzViifghYRBo9G04R97RCRBoCHwL3GGMOu8cZ61syLbpAicjFwG5jzKJk25IiZAKnAs8bYwYAxVhumErS5fmw2xVGY73w2gINqJlfHxHjFHHfBnRw229vhzkOEcnCEvY3jTEf2cG77M9p7H932+GBysUp5XUWcImIFGK54s4DnsZyL7jWB3a/tsrrtuMbA/twTnlsBbYaY+bZ+x9giX06Ph/DgY3GmD3GmFLgI6znJW2eDaeI+wKgq90SXhurQeSzJNsUc2wf4EvASmPMP9yiPgNcPRpuBD51C/+Z3StiEHDI/jz/GhghIk3tGs4IO6xGYYy53xjT3hiTi3XPpxljrgOmA1fYybzLw1VOV9jpjR0+xu4x0QnoCsxP0GXEDGPMTmCLiHS3g4YBK0jP52MzMEhE6tu/G1dZpM+zkewW3Vj9YbX8r8FqzX4g2fbE6RqHYH1SLwEW238XYfkGpwJrgW+BZnZ6Af5tl8lSIM8tr59jNQ6tA25O9rXFoGzyqeot0xnrB7gOeB+oY4fXtffX2fGd3Y5/wC6n1cCFyb6eKMqhP7DQfkY+wertkpbPB/AosApYBryB1eMlbZ4NHaGqKIriQJzillEURVHcUHFXFEVxICruiqIoDkTFXVEUxYGouCuKojgQFXdFURQHouKuKIriQFTcFUVRHMj/Bzg7STcgTgyrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsp_20_train.train_and_validate(n_epochs=5, \n",
    "                                lr_actor=0.0001, \n",
    "                                lr_critic=0.0001, \n",
    "                                scheduler_step=5000, \n",
    "                                scheduler_gamma=0.96)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
