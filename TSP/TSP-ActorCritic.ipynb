{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added critic to the code found in \n",
    "https://github.com/higgsfield/np-hard-deep-reinforcement-learning/blob/master/Neural%20Combinatorial%20Optimization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a set of 2D coordinates of length 'num_samples'\n",
    "class TSPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, num_nodes, num_samples, random_seed=111):\n",
    "        super(TSPDataset, self).__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        self.data_set = []\n",
    "        for l in tqdm(range(num_samples)):\n",
    "            x = torch.FloatTensor(2, num_nodes).uniform_(0, 1)\n",
    "            self.data_set.append(x)\n",
    "\n",
    "        self.size = len(self.data_set)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000000\n",
    "val_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:01<00:00, 510076.32it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 332501.27it/s]\n",
      "100%|██████████| 1000000/1000000 [00:02<00:00, 457638.65it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 317723.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_20_dataset = TSPDataset(20, train_size)\n",
    "val_20_dataset   = TSPDataset(20, val_size)\n",
    "\n",
    "train_50_dataset = TSPDataset(50, train_size)\n",
    "val_50_dataset   = TSPDataset(50, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 947.87it/s]\n"
     ]
    }
   ],
   "source": [
    "study_dataset = TSPDataset(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a vector of size equal to the mini-batch size\n",
    "def reward(sample_solution, USE_CUDA=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample_solution list of length 'seq_len' of [batch_size x input_size (2 since doing 2D coordinates)]\n",
    "    \"\"\"\n",
    "    batch_size = sample_solution[0].size(0)\n",
    "    n = len(sample_solution)\n",
    "    #print batch_size\n",
    "    tour_len = Variable(torch.zeros([batch_size]))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        tour_len = tour_len.cuda()\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        tour_len += torch.norm(sample_solution[i] - sample_solution[i + 1], dim=1)\n",
    "    \n",
    "    tour_len += torch.norm(sample_solution[n - 1] - sample_solution[0], dim=1)\n",
    "\n",
    "    return tour_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, use_tanh=False, C=10, name='Bahdanau', use_cuda=USE_CUDA):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.use_tanh = use_tanh\n",
    "        self.C = C\n",
    "        self.name = name\n",
    "        \n",
    "        if name == 'Bahdanau':\n",
    "            self.W_query = nn.Linear(hidden_size, hidden_size)\n",
    "            self.W_ref   = nn.Conv1d(hidden_size, hidden_size, 1, 1)\n",
    "\n",
    "            V = torch.FloatTensor(hidden_size)\n",
    "            if use_cuda:\n",
    "                V = V.cuda()  \n",
    "            self.V = nn.Parameter(V)\n",
    "            self.V.data.uniform_(-(1. / math.sqrt(hidden_size)) , 1. / math.sqrt(hidden_size))\n",
    "            \n",
    "        \n",
    "    def forward(self, query, ref):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            query: [batch_size x hidden_size]\n",
    "            ref:   ]batch_size x seq_len x hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = ref.size(0)\n",
    "        seq_len    = ref.size(1)\n",
    "        \n",
    "        if self.name == 'Bahdanau':\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "            query = self.W_query(query).unsqueeze(2)  # [batch_size x hidden_size x 1]\n",
    "            ref   = self.W_ref(ref)  # [batch_size x hidden_size x seq_len] \n",
    "            expanded_query = query.repeat(1, 1, seq_len) # [batch_size x hidden_size x seq_len]\n",
    "            V = self.V.unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1) # [batch_size x 1 x hidden_size]\n",
    "            logits = torch.bmm(V, F.tanh(expanded_query + ref)).squeeze(1)\n",
    "            \n",
    "        elif self.name == 'Dot':\n",
    "            query  = query.unsqueeze(2)\n",
    "            logits = torch.bmm(ref, query).squeeze(2) #[batch_size x seq_len x 1]\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            logits = self.C * F.tanh(logits)\n",
    "        else:\n",
    "            logits = logits  \n",
    "        return ref, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, use_cuda=USE_CUDA):\n",
    "        super(GraphEmbedding, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.embedding = nn.Parameter(torch.FloatTensor(input_size, embedding_size)) \n",
    "        self.embedding.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        embedding = self.embedding.repeat(batch_size, 1, 1)  \n",
    "        embedded = []\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        for i in range(seq_len):\n",
    "            embedded.append(torch.bmm(inputs[:, :, :, i].float(), embedding))\n",
    "        embedded = torch.cat(embedded, 1)\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            num_processing,\n",
    "            n_glimpses,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.num_processing = num_processing\n",
    "        self.use_cuda       = use_cuda\n",
    "        \n",
    "        self.embedding = GraphEmbedding(2, embedding_size, use_cuda=use_cuda)\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        #self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)  \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        #TODO change to Dima's and take care of dimensions of ref (i.e., permutation)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=True, name='Bahdanau', use_cuda=use_cuda) #Bahdanau, use_tanh=True           \n",
    "            \n",
    "        self.fc1.weight = torch.nn.init.uniform(self.fc1.weight, -0.08, 0.08)  \n",
    "        self.fc2.weight = torch.nn.init.uniform(self.fc2.weight, -0.08, 0.08)\n",
    "            \n",
    "            \n",
    "    def forward(self, inputs, input_embedded):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"        \n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        #embedded = self.embedding(inputs)\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(input_embedded)       \n",
    "        \"\"\"encoder_outputs: [batch_size x seq_len x hidden_size]\"\"\"                \n",
    "       \n",
    "        #The first input to the decoder is the last hidden state\n",
    "        #decoder_input = torch.t(hidden) #Batch size has to be the first dimension, so swap first and second dimensions\n",
    "        \n",
    "        #Init decoder's hidden and reuse the encoder's context        \n",
    "        #hidden = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "        #context = Variable(torch.zeros(context.size()))\n",
    "        \n",
    "#         print (decoder_input.size())\n",
    "        \n",
    "        query = torch.t(hidden).squeeze()        \n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(self.num_processing):                        \n",
    "            \n",
    "            #_, (hidden, context) = self.decoder(decoder_input, (hidden, context))\n",
    "            \n",
    "            #query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)            \n",
    "            \n",
    "            #Do the glimpse\n",
    "            ref, logits = self.glimpse(query, encoder_outputs)\n",
    "            #logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            query = torch.bmm(ref, F.softmax(logits).unsqueeze(2)).squeeze(2)           \n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = query#.unsqueeze(1)\n",
    "            \n",
    "        #Do fully connected part   TODO: batch norm \n",
    "        output = self.fc1(query)\n",
    "        output = F.relu(output)\n",
    "        output = self.fc2(output)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(PointerNet, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.use_cuda       = use_cuda\n",
    "        \n",
    "        \n",
    "        self.embedding = GraphEmbedding(2, embedding_size, use_cuda=use_cuda)\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.pointer = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=False, name=attention, use_cuda=use_cuda)\n",
    "        \n",
    "        self.decoder_start_input = nn.Parameter(torch.FloatTensor(embedding_size))\n",
    "        self.decoder_start_input.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    \"\"\"\n",
    "    idxs: indeces that were previously chosen\n",
    "    logits: probabilities for current step\n",
    "    \"\"\"\n",
    "    def apply_mask_to_logits(self, logits, mask, idxs): \n",
    "        batch_size = logits.size(0)\n",
    "        clone_mask = mask.clone()\n",
    "\n",
    "        if idxs is not None:\n",
    "            clone_mask[[i for i in range(batch_size)], idxs.data] = 1\n",
    "            logits[clone_mask] = -np.inf\n",
    "        return logits, clone_mask\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        \n",
    "        #The encoder simply runs the embedding\n",
    "        encoder_outputs, (hidden, context) = self.encoder(embedded)        \n",
    "        \n",
    "        prev_probs = []\n",
    "        prev_idxs = []\n",
    "        mask = torch.zeros(batch_size, seq_len).byte()\n",
    "        if self.use_cuda:\n",
    "            mask = mask.cuda()\n",
    "            \n",
    "        idxs = None\n",
    "       \n",
    "        #The first input to the decoder is learned, as in the paper\n",
    "        decoder_input = self.decoder_start_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "        \n",
    "        #For each step in the sequence\n",
    "        for i in range(seq_len):                                        \n",
    "                \n",
    "            _, (hidden, context) = self.decoder(decoder_input.unsqueeze(1), (hidden, context))\n",
    "            \n",
    "            query = hidden.squeeze(0) #[hidden_size x 1] (or the other way around)\n",
    "            \n",
    "            for i in range(self.n_glimpses):\n",
    "                ref, logits = self.glimpse(query, encoder_outputs)\n",
    "                logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "                query = torch.bmm(ref, F.softmax(logits).unsqueeze(2)).squeeze(2)                 \n",
    "                \n",
    "            _, logits = self.pointer(query, encoder_outputs)\n",
    "            logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            \n",
    "            #[batch size x seq_len]\n",
    "            probs = F.softmax(logits)\n",
    "            \n",
    "            #Give me the index that will be chosen: [batch_size]\n",
    "            idxs = probs.multinomial().squeeze(1)\n",
    "            \n",
    "            for old_idxs in prev_idxs:\n",
    "                if old_idxs.eq(idxs).data.any():\n",
    "                    print seq_len\n",
    "                    print(' RESAMPLE!')\n",
    "                    idxs = probs.multinomial().squeeze(1)\n",
    "                    break\n",
    "                    \n",
    "            #[batch_size x hidden_size]\n",
    "            decoder_input = embedded[range(batch_size), idxs.data, :] \n",
    "            \n",
    "            prev_probs.append(probs)\n",
    "            prev_idxs.append(idxs)\n",
    "            \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        return prev_probs, prev_idxs, embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialRL(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            reward,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(CombinatorialRL, self).__init__()\n",
    "        self.reward = reward\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.actor = PointerNet(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                seq_len,\n",
    "                n_glimpses,\n",
    "                tanh_exploration,\n",
    "                use_tanh,\n",
    "                attention,\n",
    "                use_cuda)\n",
    "        \n",
    "        self.critic = Critic(embedding_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            seq_len=seq_len,\n",
    "            num_processing=3,\n",
    "            n_glimpses=n_glimpses,\n",
    "            use_cuda=use_cuda)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch_size, input_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        input_size = inputs.size(1) #2 because we are doing 2D coordinates\n",
    "        seq_len    = inputs.size(2)        \n",
    "                \n",
    "        #list of seq_len containing[batch_size x seq_len], list of seq_len containing [batch_size]    \n",
    "        probs, action_idxs, input_embedded = self.actor(inputs)\n",
    "                        \n",
    "        critic_evals = self.critic(inputs, input_embedded)\n",
    "        \n",
    "#         print (\"Combinatorial RL (inputs)\")\n",
    "#         print (inputs)\n",
    "        #print (\"Combinatorial RL (action_idxs.size): \", action_idxs)\n",
    "       \n",
    "        actions = []\n",
    "        \n",
    "        \"\"\"\n",
    "        Transpose the inputs to have [batch_size, seq_len, input_size]\n",
    "        \"\"\"\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        \n",
    "        #List of size seq_len\n",
    "        for action_id in action_idxs:\n",
    "            actions.append(inputs[range(batch_size), action_id.data, :])\n",
    "            \n",
    "        #actions now has the coordinates in the solution            \n",
    "        action_probs = []    \n",
    "        #List of size seq_len\n",
    "        for prob, action_id in zip(probs, action_idxs):\n",
    "            #We want to know the probability of taking each action (picking city) in the solution\n",
    "            action_probs.append(prob[range(batch_size), action_id.data])\n",
    "\n",
    "        #R is [batch_size x 1]\n",
    "        R = self.reward(actions, self.use_cuda)\n",
    "        \n",
    "        return R, action_probs, actions, action_idxs, critic_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size    = 128\n",
    "n_glimpses = 1\n",
    "tanh_exploration = 10\n",
    "use_tanh = True\n",
    "\n",
    "beta = 0.9\n",
    "max_grad_norm = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        20,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        reward,\n",
    "        attention=\"Dot\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_50_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        50,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        reward,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_5_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        5,\n",
    "        n_glimpses,\n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        reward,\n",
    "        attention='Dot',\n",
    "        use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, model, train_dataset, val_dataset, batch_size=128, threshold=None, max_grad_norm=2.):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset   = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        self.val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        self.actor_optim   = optim.Adam(model.actor.parameters(), lr=0.0001)\n",
    "        self.critic_optim  = optim.Adam(model.critic.parameters(), lr=0.0001)\n",
    "        self.scheduler_actor = optim.lr_scheduler.StepLR(self.actor_optim, step_size=5000, gamma=0.96)\n",
    "        self.scheduler_critic = optim.lr_scheduler.StepLR(self.critic_optim, step_size=5000, gamma=0.96)\n",
    "        \n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "        self.train_tour = []\n",
    "        self.val_tour   = []\n",
    "        \n",
    "        self.epochs = 0\n",
    "    \n",
    "    def train_and_validate(self, n_epochs):\n",
    "        critic_exp_mvg_avg = torch.zeros(1)\n",
    "        critic_loss_criterion = torch.nn.MSELoss()        \n",
    "        \n",
    "        if USE_CUDA: \n",
    "            critic_exp_mvg_avg = critic_exp_mvg_avg.cuda()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_id, sample_batch in enumerate(self.train_loader):\n",
    "                self.model.train()\n",
    "                \n",
    "                self.scheduler_actor.step()\n",
    "                self.scheduler_critic.step()\n",
    "                \n",
    "                inputs = Variable(sample_batch)\n",
    "                \n",
    "                if USE_CUDA:\n",
    "                    inputs = inputs.cuda()\n",
    "\n",
    "                #Model is combinatorial\n",
    "                R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "\n",
    "                if batch_id == 0:\n",
    "                    critic_exp_mvg_avg = R.mean()\n",
    "                else:\n",
    "                    critic_exp_mvg_avg = (critic_exp_mvg_avg * beta) + ((1. - beta) * R.mean())\n",
    "\n",
    "                #Vector of length equal to the mini-batch size: Q(s,a) - V(s)\n",
    "                #advantage = R - critic_exp_mvg_avg                \n",
    "                advantage = R.unsqueeze(1) - values\n",
    "                \n",
    "                print (\"Advantage function: \", R.mean() - values.mean())\n",
    "\n",
    "                logprobs = 0\n",
    "                for prob in probs: \n",
    "                    logprob = torch.log(prob)\n",
    "                    logprobs += logprob\n",
    "                    \n",
    "                #logprobs[logprobs < -1000] = 0. #Works with PyTorch 2.0\n",
    "                                \n",
    "                #For Pytorch 3.0                                \n",
    "                if logprobs.data[0] < -1000:\n",
    "                    print (logprobs.data[0])\n",
    "                    logprobs = Variable(torch.FloatTensor([0.]), requires_grad=True)\n",
    "\n",
    "                reinforce = advantage * logprobs\n",
    "                actor_loss = reinforce.mean()\n",
    "\n",
    "                self.actor_optim.zero_grad()                \n",
    "                actor_loss.backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm(self.model.actor.parameters(),\n",
    "                                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.actor_optim.step()\n",
    "                \n",
    "                #Do critic gradient descent\n",
    "                self.critic_optim.zero_grad()\n",
    "                loss_critic = critic_loss_criterion(values, R.unsqueeze(1))\n",
    "                loss_critic.backward()\n",
    "                torch.nn.utils.clip_grad_norm(self.model.critic.parameters(),\n",
    "                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.critic_optim.step()\n",
    "                #print (\"Critic's loss: \", loss_critic.data[0])\n",
    "                \n",
    "                #critic_exp_mvg_avg = critic_exp_mvg_avg.detach()\n",
    "\n",
    "                self.train_tour.append(R.mean().data[0])\n",
    "\n",
    "                if batch_id % 10 == 0:\n",
    "                    self.plot(self.epochs)\n",
    "\n",
    "#                 if batch_id % 100 == 0:    \n",
    "\n",
    "#                     self.model.eval()\n",
    "#                     for val_batch in self.val_loader:\n",
    "#                         inputs = Variable(val_batch)\n",
    "                        \n",
    "#                         if USE_CUDA:\n",
    "#                             inputs = inputs.cuda()\n",
    "\n",
    "#                         R, probs, actions, actions_idxs, values = self.model(inputs)\n",
    "#                         self.val_tour.append(R.mean().data[0])\n",
    "\n",
    "            if self.threshold and self.train_tour[-1] < self.threshold:\n",
    "                print \"EARLY STOPPAGE!\"\n",
    "                break\n",
    "                \n",
    "            self.epochs += 1\n",
    "                \n",
    "    def plot(self, epoch):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train tour length: epoch %s reward %s' % (epoch, self.train_tour[-1] if len(self.train_tour) else 'collecting'))\n",
    "        plt.plot(self.train_tour)\n",
    "        plt.grid()\n",
    "#         plt.subplot(132)\n",
    "#         plt.title('val tour length: epoch %s reward %s' % (epoch, self.val_tour[-1] if len(self.val_tour) else 'collecting'))\n",
    "#         plt.plot(self.val_tour)\n",
    "#         plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_train = TrainModel(tsp_20_model, \n",
    "                        train_20_dataset, \n",
    "                        val_20_dataset, \n",
    "                        threshold=3.99)\n",
    "\n",
    "tsp_5_train = TrainModel(tsp_5_model, study_dataset,\n",
    "                        study_dataset, threshold=3.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Advantage function: ', Variable containing:\n",
      " 0.2039\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "1.00000e-02 *\n",
      "  6.3038\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "1.00000e-02 *\n",
      "  3.3143\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      " 0.1618\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "-0.1318\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "1.00000e-02 *\n",
      "  3.3790\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "-0.2244\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('Advantage function: ', Variable containing:\n",
      "1.00000e-02 *\n",
      "  4.8427\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tsp_20_train.train_and_validate(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
