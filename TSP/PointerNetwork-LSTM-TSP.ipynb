{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "LENGTH_SEQ = 5\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def next_batch(self, batch_size, N, train_mode=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "\n",
    "        # A sequence of random numbers from [0, 1]\n",
    "        encoder_batch = []\n",
    "\n",
    "        # Sorted sequence that we feed to encoder\n",
    "        # In inference we feed an unordered sequence again\n",
    "        decoder_batch = []\n",
    "\n",
    "        # Ordered sequence where one hot vector encodes\n",
    "        # position in the input array\n",
    "        target_batch = []\n",
    "        for _ in range(batch_size):\n",
    "            encoder_batch.append(np.zeros([N, 1]))\n",
    "        for _ in range(batch_size):\n",
    "            decoder_batch.append(np.zeros([N, 1]))\n",
    "            target_batch.append(np.zeros([N, N]))\n",
    "\n",
    "        encoder_batch = np.asarray(encoder_batch)\n",
    "        decoder_batch = np.asarray(decoder_batch)\n",
    "        target_batch = np.asarray(target_batch)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            shuffle = np.random.permutation(N)\n",
    "            sequence = np.sort(np.random.random(N))\n",
    "            shuffled_sequence = sequence[shuffle]\n",
    "\n",
    "            for i in range(N):\n",
    "                encoder_batch[b][i] = shuffled_sequence[i]\n",
    "                if train_mode:\n",
    "                    decoder_batch[b][i] = sequence[i]\n",
    "                else:\n",
    "                    decoder_batch[b][i] = shuffled_sequence[i]\n",
    "                target_batch[b, i][shuffle[i]] = 1.0\n",
    "\n",
    "            # Points to the stop symbol\n",
    "            #target_batch[b, N][0] = 1.0\n",
    "\n",
    "        return encoder_batch, decoder_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "LENGTH_SEQ = 10\n",
    "\n",
    "class Tsp:\n",
    "    def next_batch(self, batch_size=1):\n",
    "        X, Y = [], []\n",
    "        for b in range(batch_size):\n",
    "            #print(\"preparing dataset... %s/%s\" % (b, batch_size))\n",
    "            points = self.generate_data()\n",
    "            solved = self.solve_tsp_dynamic(points)\n",
    "            X.append(points), Y.append(solved)\n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "    def length(self, x, y):\n",
    "        return (math.sqrt((x[0]-y[0])**2 + (x[1]-y[1])**2))\n",
    "\n",
    "    def solve_tsp_dynamic(self, points):\n",
    "        # calc all lengths\n",
    "        all_distances = [[self.length(x, y) for y in points] for x in points]\n",
    "        # initial value - just distance from 0 to\n",
    "        # every other point + keep the track of edges\n",
    "        A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1])\n",
    "             for idx, dist in enumerate(all_distances[0][1:])}\n",
    "        cnt = len(points)\n",
    "        for m in range(2, cnt):\n",
    "            B = {}\n",
    "            for S in [frozenset(C) | {0}\n",
    "                      for C in itertools.combinations(range(1, cnt), m)]:\n",
    "                for j in S - {0}:\n",
    "                    B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j],\n",
    "                                      A[(S-{j}, k)][1] + [j])\n",
    "                                     for k in S if k != 0 and k != j])\n",
    "            A = B\n",
    "        res = min([(A[d][0] + all_distances[0][d[1]], A[d][1])\n",
    "                   for d in iter(A)])\n",
    "        return res[1]\n",
    "\n",
    "    def generate_data(self, N=LENGTH_SEQ):\n",
    "        radius = 1\n",
    "        rangeX = (0, 10)\n",
    "        rangeY = (0, 10)\n",
    "        qty = N\n",
    "\n",
    "        deltas = set()\n",
    "        for x in range(-radius, radius+1):\n",
    "            for y in range(-radius, radius+1):\n",
    "                if x*x + y*y <= radius*radius:\n",
    "                    deltas.add((x, y))\n",
    "\n",
    "        randPoints = []\n",
    "        excluded = set()\n",
    "        i = 0\n",
    "        while i < qty:\n",
    "            x = random.randrange(*rangeX)\n",
    "            y = random.randrange(*rangeY)\n",
    "            if (x, y) in excluded:\n",
    "                continue\n",
    "            randPoints.append((x, y))\n",
    "            i += 1\n",
    "            excluded.update((x+dx, y+dy) for (dx, dy) in deltas)\n",
    "        return randPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Tsp()\n",
    "\n",
    "#Returns tuple of 3 elements: inputs, inputs ordered acc. to solution, solution in one-hot encoding\n",
    "def generate_tsp_batch(batch_size=32):\n",
    "\n",
    "    input_pts, soln = dataset.next_batch(batch_size)\n",
    "    soln_pts_batched = np.zeros(input_pts.shape)\n",
    "    soln_one_hot = np.zeros((batch_size, soln.shape[1], soln.shape[1]))\n",
    "\n",
    "    #print (soln)\n",
    "\n",
    "    for i in range(soln.shape[0]):\n",
    "        soln_pts_batched[i] = input_pts[i, soln[i]]\n",
    "        temp = np.zeros((soln.shape[1], soln.shape[1]))    \n",
    "        temp[np.arange(soln.shape[1]), soln[i]] = 1.0\n",
    "        soln_one_hot[i] = temp\n",
    "\n",
    "    input_pts_batched = torch.transpose(torch.from_numpy(input_pts), 0, 1)    \n",
    "    soln_pts_batched = torch.transpose(torch.from_numpy(soln_pts_batched), 0, 1)\n",
    "    soln_one_hot_batched = torch.transpose(torch.from_numpy(soln_one_hot).float(), 0, 1)\n",
    "\n",
    "    #print (soln_one_hot_batched)\n",
    "    return input_pts_batched, soln_pts_batched, soln_one_hot_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]]\n",
      "(5, 10)\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "test = DataGenerator()\n",
    "batch_size=2\n",
    "enc_in, dec_in, targets = test.next_batch(batch_size=batch_size, N=5)\n",
    "#print (enc_in)\n",
    "print (targets)\n",
    "\n",
    "i = 0\n",
    "enc_in_batch = enc_in[0]\n",
    "dec_in_batch = dec_in[0]\n",
    "targets_batch = targets[0]\n",
    "\n",
    "targetss = np.zeros((batch_size, 5))\n",
    "\n",
    "while i < batch_size-1:\n",
    "    enc_in_batch = np.concatenate((enc_in_batch, enc_in[i+1]), axis=1)\n",
    "    dec_in_batch = np.concatenate((dec_in_batch, dec_in[i+1]), axis=1)\n",
    "    targets_batch = np.concatenate((targets_batch, targets[i+1]), axis=1)\n",
    "    i+=1\n",
    "    \n",
    "print (targets_batch.shape)\n",
    "\n",
    "for i in range(5):\n",
    "    print (targets_batch[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(enc_input, dec_input, batch_size, targets, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()                    \n",
    "        \n",
    "    input_length = dec_input.size()[0]\n",
    "    target_length = dec_input.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(input_length, batch_size, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #Pass every token to the encoder, one at a time\n",
    "    #The output is stored for when we use attention\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            enc_input[ei], encoder_hidden)\n",
    "        \n",
    "        #print (encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0]\n",
    "\n",
    "    #decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    #decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    #The first hidden state of the decoder is the last hidden state of the encoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        \n",
    "        if di == 0:\n",
    "            decoder_input = decoder.first_step_input\n",
    "        else:\n",
    "            #pointers = \n",
    "            _, pointers = torch.max(decoder_attention, dim=1)\n",
    "            #inputs = enc_input[pointers.data.squeeze()]\n",
    "            #print (pointers.data)\n",
    "            #print (enc_input)\n",
    "#             print (\"pointers \", pointers.data.squeeze())\n",
    "#             print (\"inputs\", enc_input)\n",
    "#             print (\"enc_input T\", torch.transpose(enc_input,0,1))\n",
    "#             print (\"print inputs pointed\", torch.transpose(enc_input,0,1)[range(batch_size), pointers.data.squeeze()])\n",
    "            #print (pointers.data)\n",
    "            #print (enc_input.size())\n",
    "            #print (pointers.size())\n",
    "            #Pass the next city to the decoder as the input\n",
    "            decoder_input = torch.transpose(enc_input,0,1)[range(batch_size), pointers.data.squeeze()]\n",
    "\n",
    "        #decoder_input = dec_input[di]  # Teacher forcing\n",
    "        #print (decoder_input.size())\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs, di)\n",
    "    \n",
    "        predictions.append(decoder_attention)\n",
    "    \n",
    "    #Compare the one-hot vectors with predictions\n",
    "    predictions = torch.stack(predictions).squeeze()\n",
    "    \n",
    "#     print (predictions)\n",
    "#     print (targets)\n",
    "#     print (torch.transpose(targets, 0, 1))\n",
    "    \n",
    "    #_, index_targets = torch.max(targets, dim=1)\n",
    "    #_, index_predictions = torch.max(predictions, dim=1)\n",
    "    \n",
    "    loss += criterion(predictions, targets)\n",
    "    #loss += criterion(predictions, index_targets)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, batch_size, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()#nn.NLLLoss()#          \n",
    "\n",
    "    for iter in range(1, n_iters + 1):                \n",
    "        enc_input, dec_input, targets = generate_tsp_batch(batch_size)\n",
    "        \n",
    "        targets = Variable(targets, volatile=True)\n",
    "        \n",
    "        loss = train(enc_input, dec_input, batch_size, targets, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        #plays role of embedding of D=hidden_size\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.embedding.weight = torch.nn.init.xavier_uniform(self.embedding.weight)\n",
    "        \n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        \n",
    "    #Input contains the sequence at time t for the mini-batch\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        embedded = self.embedding(Variable(input.float())).view(1, self.batch_size, self.hidden_size)\n",
    "        embedded = self.dropout(embedded)  \n",
    "        \n",
    "        #embedded = Variable(input.float()).view(1, self.batch_size, self.input_size)       \n",
    "        output, hidden = self.rnn(embedded, hidden)  \n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        #result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        result = (Variable(torch.zeros(1, self.batch_size, self.hidden_size)),\n",
    "          Variable(torch.zeros((1, self.batch_size, self.hidden_size))))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtrDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, batch_size, sequence_length=10, dropout_p=0.1):\n",
    "        super(PtrDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size        \n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.attn2 = nn.Linear(self.hidden_size * 2, self.hidden_size) #as in the paper\n",
    "        self.attn2.weight = torch.nn.init.xavier_uniform(self.attn2.weight)\n",
    "                \n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size)       \n",
    "        self.V = nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        #plays role of embedding of D=hidden_size\n",
    "        self.embedding = nn.Linear(output_size, hidden_size)\n",
    "        self.embedding.weight = torch.nn.init.xavier_uniform(self.embedding.weight)\n",
    "        \n",
    "        self.first_step_input = nn.Parameter(torch.rand(self.hidden_size))\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, di):                \n",
    "                \n",
    "        #embedded = Variable(input.float()).view(1, self.batch_size, self.output_size)    \n",
    "        #Input to the first decoder step is learned\n",
    "        if di == 0:\n",
    "            embedded = self.first_step_input.repeat(self.batch_size).view(1, self.batch_size, self.hidden_size)\n",
    "        else:\n",
    "            embedded = self.embedding(Variable(input.float())).view(1, self.batch_size, self.hidden_size)\n",
    "        \n",
    "        embedded = self.dropout(embedded)  \n",
    "        \n",
    "        repeated_hidden = hidden[0].repeat(self.sequence_length, 1, 1)\n",
    "\n",
    "        input_alignment = torch.cat((repeated_hidden, encoder_outputs), 2)                \n",
    "        \n",
    "        non_linearity = F.tanh(self.attn2(input_alignment)).squeeze()                           \n",
    "                \n",
    "        to_softmax = torch.matmul(non_linearity, self.V)\n",
    "        \n",
    "        #Compute the attention weights as in Dima's paper\n",
    "        es = F.softmax(to_softmax, dim = 0)\n",
    "        attn_weights = torch.transpose(es, 0, 1)                      \n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)            \n",
    "                \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        #1 because we are doing one line of the sequence at a time\n",
    "        result = (Variable(torch.zeros(1, self.batch_size, self.hidden_size)),\n",
    "            Variable(torch.zeros((1, self.batch_size, self.hidden_size))))\n",
    "        \n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 35s (- 158m 16s) (100 1%) 0.0081\n",
      "3m 3s (- 149m 27s) (200 2%) 0.0078\n",
      "4m 31s (- 146m 3s) (300 3%) 0.0074\n",
      "5m 57s (- 143m 7s) (400 4%) 0.0072\n",
      "7m 23s (- 140m 30s) (500 5%) 0.0071\n",
      "9m 0s (- 141m 8s) (600 6%) 0.0070\n",
      "10m 28s (- 139m 13s) (700 7%) 0.0070\n",
      "11m 54s (- 136m 59s) (800 8%) 0.0069\n",
      "13m 21s (- 135m 7s) (900 9%) 0.0069\n",
      "14m 57s (- 134m 35s) (1000 10%) 0.0068\n",
      "16m 27s (- 133m 11s) (1100 11%) 0.0068\n",
      "18m 6s (- 132m 50s) (1200 12%) 0.0068\n",
      "19m 45s (- 132m 15s) (1300 13%) 0.0067\n",
      "21m 21s (- 131m 9s) (1400 14%) 0.0067\n",
      "22m 48s (- 129m 14s) (1500 15%) 0.0067\n",
      "24m 14s (- 127m 15s) (1600 16%) 0.0067\n",
      "25m 40s (- 125m 21s) (1700 17%) 0.0066\n",
      "27m 11s (- 123m 52s) (1800 18%) 0.0066\n",
      "28m 52s (- 123m 4s) (1900 19%) 0.0066\n",
      "30m 32s (- 122m 9s) (2000 20%) 0.0066\n",
      "32m 15s (- 121m 19s) (2100 21%) 0.0065\n",
      "33m 48s (- 119m 50s) (2200 22%) 0.0065\n",
      "35m 24s (- 118m 31s) (2300 23%) 0.0065\n",
      "36m 52s (- 116m 45s) (2400 24%) 0.0065\n",
      "38m 23s (- 115m 9s) (2500 25%) 0.0065\n",
      "39m 49s (- 113m 22s) (2600 26%) 0.0064\n",
      "41m 20s (- 111m 45s) (2700 27%) 0.0064\n",
      "42m 47s (- 110m 3s) (2800 28%) 0.0064\n",
      "44m 18s (- 108m 29s) (2900 28%) 0.0063\n",
      "45m 45s (- 106m 46s) (3000 30%) 0.0063\n",
      "47m 25s (- 105m 33s) (3100 31%) 0.0063\n",
      "49m 7s (- 104m 24s) (3200 32%) 0.0064\n",
      "60m 26s (- 122m 42s) (3300 33%) 0.0063\n",
      "61m 51s (- 120m 4s) (3400 34%) 0.0063\n",
      "63m 16s (- 117m 30s) (3500 35%) 0.0062\n",
      "64m 41s (- 115m 0s) (3600 36%) 0.0063\n",
      "66m 8s (- 112m 36s) (3700 37%) 0.0062\n",
      "67m 33s (- 110m 12s) (3800 38%) 0.0062\n",
      "68m 58s (- 107m 52s) (3900 39%) 0.0062\n",
      "70m 23s (- 105m 35s) (4000 40%) 0.0062\n",
      "71m 48s (- 103m 20s) (4100 41%) 0.0062\n",
      "73m 13s (- 101m 7s) (4200 42%) 0.0061\n",
      "74m 39s (- 98m 58s) (4300 43%) 0.0061\n",
      "76m 4s (- 96m 49s) (4400 44%) 0.0062\n",
      "77m 29s (- 94m 43s) (4500 45%) 0.0062\n",
      "78m 54s (- 92m 38s) (4600 46%) 0.0061\n",
      "80m 19s (- 90m 35s) (4700 47%) 0.0060\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 64 #8 works well\n",
    "encoder3 = EncoderRNN(input_size=2, hidden_size=hidden_size, batch_size=batch_size)\n",
    "attn_decoder3 = PtrDecoderRNN(hidden_size=hidden_size, output_size=2, batch_size=batch_size)\n",
    "\n",
    "# if use_cuda:\n",
    "#     encoder2 = encoder1.cuda()\n",
    "#     attn_decoder2 = attn_decoder1.cuda()\n",
    "\n",
    "#trainIters(encoder, attn_decoder, 50000, print_every=1000, learning_rate=0.0001) #For NLLoss\n",
    "#For MSELoss:0.001, 0.0001, 0.00001 after 50,000 updates\n",
    "trainIters(encoder3, attn_decoder3, batch_size, 10000, print_every=100, learning_rate=0.001) \n",
    "#p, t = evaluate(encoder, attn_decoder, 1)\n",
    "#10,000 updates -> 0.007 from 0.0084\n",
    "\n",
    "#print (np.round(p.data.numpy(),1), t)\n",
    "\n",
    "# _, index_target = torch.max(t, dim=1)\n",
    "# _, index_prediction = torch.max(p, dim=1)\n",
    "# print (index_target)\n",
    "# print (index_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t = evaluate(encoder, attn_decoder, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 2 1 4 7 7 9 8 9]\n",
      "[0 9 8 7 3 4 5 1 2 6]\n",
      "Error rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "num_batches = 1\n",
    "num_errors = 0.0\n",
    "\n",
    "for j in range(num_batches):\n",
    "\n",
    "    p, t = evaluate(encoder, attn_decoder, batch_size)\n",
    "    \n",
    "    p = torch.transpose(p, 0, 1)\n",
    "    t = torch.transpose(t, 0, 1)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #prediction = torch.transpose(p.data, 0, 1)[i].numpy().argmax(axis=1)\n",
    "        #target = t.data[i].numpy().argmax(axis=1)                \n",
    "        \n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "            print (p[i].data.numpy().argmax(axis=1))\n",
    "            print (t[i].numpy().argmax(axis=1))\n",
    "#         if (prediction == target).all() == False:\n",
    "#             print (prediction)\n",
    "#             print (target)\n",
    "#             print (\"--\")\n",
    "#             num_errors +=1\n",
    "        \n",
    "print (\"Error rate: \", num_errors/(num_batches*batch_size)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, batch_size):\n",
    "    enc_input, dec_input, targets = generate_tsp_batch(batch_size)      \n",
    "    \n",
    "    dec_input = enc_input # we don't want to feed the answer\n",
    "        \n",
    "    input_length = dec_input.size()[0]\n",
    "    target_length = dec_input.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(input_length, batch_size, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    #Pass every token to the encoder, one at a time\n",
    "    #The output is stored for when we use attention\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            enc_input[ei], encoder_hidden)\n",
    "        \n",
    "        #print (encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0]\n",
    "\n",
    "    #The first hidden state of the decoder is the last hidden state of the encoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for di in range(target_length):\n",
    "\n",
    "        decoder_input = dec_input[di]\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    \n",
    "        predictions.append(decoder_attention)\n",
    "    \n",
    "    #Compare the one-hot vectors with predictions\n",
    "    predictions = torch.stack(predictions).squeeze()\n",
    "    \n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "batch_size = 1\n",
    "dataset = DataGenerator()\n",
    "enc_input, dec_input, targets = dataset.next_batch(batch_size, seq_len)\n",
    "print(\"batch_size\", batch_size, \"seq_len\", seq_len)\n",
    "print(\"-------------encoder input-------------\")\n",
    "print(enc_input.shape)\n",
    "print(enc_input)\n",
    "print(\"-------------decoder input-------------\")\n",
    "print(dec_input.shape)\n",
    "print(dec_input)\n",
    "print(\"-------------   targets   -------------\")\n",
    "print(targets.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.3759  0.1582  0.8439\n",
      "-1.0646 -0.2280 -0.2801\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3477  0.1061  0.0446\n",
      "  0.1848 -0.0446 -0.2955\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 1.0165 -0.0799  0.1245\n",
      "-1.4291  0.3612  1.2956\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.2771  0.0416 -0.1618\n",
      "  0.2204  0.2445 -0.4466\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.4057 -1.3889 -0.0718\n",
      " 0.3829 -0.1459  0.7754\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.2205  0.0333 -0.2364\n",
      "  0.2669  0.1927 -0.3731\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.1505  0.8445  0.3930\n",
      " 0.9456 -0.5531  1.7102\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3307  0.1239 -0.2493\n",
      "  0.4191  0.1463 -0.4073\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.5124 -1.8215 -0.5779\n",
      "-0.1179  0.4724  2.4272\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.1345  0.0521 -0.2440\n",
      "  0.5298  0.1887 -0.5275\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [Variable(torch.randn((2, 3)))\n",
    "          for _ in range(5)]  # my sequence has five elements of 3 dimensions\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (Variable(torch.randn(1, 2, 3)),\n",
    "          Variable(torch.randn((1, 2, 3))))\n",
    "for i in inputs:\n",
    "    \n",
    "    print (i)\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 2, -1), hidden)\n",
    "    \n",
    "    print (\"out\", out)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "# inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "# hidden = (Variable(torch.randn(1, 1, 3)), Variable(\n",
    "#     torch.randn((1, 1, 3))))  # clean out hidden state\n",
    "# out, hidden = lstm(inputs, hidden)\n",
    "\n",
    "# print (\"---\")\n",
    "# print(out)\n",
    "# print(hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
