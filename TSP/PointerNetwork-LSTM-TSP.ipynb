{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "LENGTH_SEQ = 5\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    def next_batch(self, batch_size, N, train_mode=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "\n",
    "        # A sequence of random numbers from [0, 1]\n",
    "        encoder_batch = []\n",
    "\n",
    "        # Sorted sequence that we feed to encoder\n",
    "        # In inference we feed an unordered sequence again\n",
    "        decoder_batch = []\n",
    "\n",
    "        # Ordered sequence where one hot vector encodes\n",
    "        # position in the input array\n",
    "        target_batch = []\n",
    "        for _ in range(batch_size):\n",
    "            encoder_batch.append(np.zeros([N, 1]))\n",
    "        for _ in range(batch_size):\n",
    "            decoder_batch.append(np.zeros([N, 1]))\n",
    "            target_batch.append(np.zeros([N, N]))\n",
    "\n",
    "        encoder_batch = np.asarray(encoder_batch)\n",
    "        decoder_batch = np.asarray(decoder_batch)\n",
    "        target_batch = np.asarray(target_batch)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            shuffle = np.random.permutation(N)\n",
    "            sequence = np.sort(np.random.random(N))\n",
    "            shuffled_sequence = sequence[shuffle]\n",
    "\n",
    "            for i in range(N):\n",
    "                encoder_batch[b][i] = shuffled_sequence[i]\n",
    "                if train_mode:\n",
    "                    decoder_batch[b][i] = sequence[i]\n",
    "                else:\n",
    "                    decoder_batch[b][i] = shuffled_sequence[i]\n",
    "                target_batch[b, i][shuffle[i]] = 1.0\n",
    "\n",
    "            # Points to the stop symbol\n",
    "            #target_batch[b, N][0] = 1.0\n",
    "\n",
    "        return encoder_batch, decoder_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "LENGTH_SEQ = 10\n",
    "\n",
    "class Tsp:\n",
    "    def next_batch(self, batch_size=1):\n",
    "        X, Y = [], []\n",
    "        for b in range(batch_size):\n",
    "            #print(\"preparing dataset... %s/%s\" % (b, batch_size))\n",
    "            points = self.generate_data()\n",
    "            solved = self.solve_tsp_dynamic(points)\n",
    "            X.append(points), Y.append(solved)\n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "    def length(self, x, y):\n",
    "        return (math.sqrt((x[0]-y[0])**2 + (x[1]-y[1])**2))\n",
    "\n",
    "    def solve_tsp_dynamic(self, points):\n",
    "        # calc all lengths\n",
    "        all_distances = [[self.length(x, y) for y in points] for x in points]\n",
    "        # initial value - just distance from 0 to\n",
    "        # every other point + keep the track of edges\n",
    "        A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1])\n",
    "             for idx, dist in enumerate(all_distances[0][1:])}\n",
    "        cnt = len(points)\n",
    "        for m in range(2, cnt):\n",
    "            B = {}\n",
    "            for S in [frozenset(C) | {0}\n",
    "                      for C in itertools.combinations(range(1, cnt), m)]:\n",
    "                for j in S - {0}:\n",
    "                    B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j],\n",
    "                                      A[(S-{j}, k)][1] + [j])\n",
    "                                     for k in S if k != 0 and k != j])\n",
    "            A = B\n",
    "        res = min([(A[d][0] + all_distances[0][d[1]], A[d][1])\n",
    "                   for d in iter(A)])\n",
    "        return res[1]\n",
    "\n",
    "    def generate_data(self, N=LENGTH_SEQ):\n",
    "        radius = 1\n",
    "        rangeX = (0, 10)\n",
    "        rangeY = (0, 10)\n",
    "        qty = N\n",
    "\n",
    "        deltas = set()\n",
    "        for x in range(-radius, radius+1):\n",
    "            for y in range(-radius, radius+1):\n",
    "                if x*x + y*y <= radius*radius:\n",
    "                    deltas.add((x, y))\n",
    "\n",
    "        randPoints = []\n",
    "        excluded = set()\n",
    "        i = 0\n",
    "        while i < qty:\n",
    "            x = random.randrange(*rangeX)\n",
    "            y = random.randrange(*rangeY)\n",
    "            if (x, y) in excluded:\n",
    "                continue\n",
    "            randPoints.append((x, y))\n",
    "            i += 1\n",
    "            excluded.update((x+dx, y+dy) for (dx, dy) in deltas)\n",
    "        return randPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Tsp()\n",
    "\n",
    "#Returns tuple of 3 elements: inputs, inputs ordered acc. to solution, solution in one-hot encoding\n",
    "def generate_tsp_batch(batch_size=32):\n",
    "\n",
    "    input_pts, soln = dataset.next_batch(batch_size)\n",
    "    soln_pts_batched = np.zeros(input_pts.shape)\n",
    "    soln_one_hot = np.zeros((batch_size, soln.shape[1], soln.shape[1]))\n",
    "\n",
    "    #print (soln)\n",
    "\n",
    "    for i in range(soln.shape[0]):\n",
    "        soln_pts_batched[i] = input_pts[i, soln[i]]\n",
    "        temp = np.zeros((soln.shape[1], soln.shape[1]))    \n",
    "        temp[np.arange(soln.shape[1]), soln[i]] = 1.0\n",
    "        soln_one_hot[i] = temp\n",
    "\n",
    "    input_pts_batched = torch.transpose(torch.from_numpy(input_pts), 0, 1)    \n",
    "    soln_pts_batched = torch.transpose(torch.from_numpy(soln_pts_batched), 0, 1)\n",
    "    soln_one_hot_batched = torch.transpose(torch.from_numpy(soln_one_hot).float(), 0, 1)\n",
    "\n",
    "    #print (soln_one_hot_batched)\n",
    "    return input_pts_batched, soln_pts_batched, soln_one_hot_batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]]\n",
      "(5, 10)\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "test = DataGenerator()\n",
    "batch_size=2\n",
    "enc_in, dec_in, targets = test.next_batch(batch_size=batch_size, N=5)\n",
    "#print (enc_in)\n",
    "print (targets)\n",
    "\n",
    "i = 0\n",
    "enc_in_batch = enc_in[0]\n",
    "dec_in_batch = dec_in[0]\n",
    "targets_batch = targets[0]\n",
    "\n",
    "targetss = np.zeros((batch_size, 5))\n",
    "\n",
    "while i < batch_size-1:\n",
    "    enc_in_batch = np.concatenate((enc_in_batch, enc_in[i+1]), axis=1)\n",
    "    dec_in_batch = np.concatenate((dec_in_batch, dec_in[i+1]), axis=1)\n",
    "    targets_batch = np.concatenate((targets_batch, targets[i+1]), axis=1)\n",
    "    i+=1\n",
    "    \n",
    "print (targets_batch.shape)\n",
    "\n",
    "for i in range(5):\n",
    "    print (targets_batch[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(enc_input, dec_input, batch_size, targets, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()                    \n",
    "        \n",
    "    input_length = dec_input.size()[0]\n",
    "    target_length = dec_input.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(input_length, batch_size, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    #Pass every token to the encoder, one at a time\n",
    "    #The output is stored for when we use attention\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            enc_input[ei], encoder_hidden)\n",
    "        \n",
    "        #print (encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0]\n",
    "\n",
    "    #decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    #decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    #The first hidden state of the decoder is the last hidden state of the encoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for di in range(target_length):\n",
    "\n",
    "        decoder_input = dec_input[di]  # Teacher forcing\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    \n",
    "        predictions.append(decoder_attention)\n",
    "    \n",
    "    #Compare the one-hot vectors with predictions\n",
    "    predictions = torch.stack(predictions).squeeze()\n",
    "    \n",
    "#     print (predictions)\n",
    "#     print (targets)\n",
    "#     print (torch.transpose(targets, 0, 1))\n",
    "    \n",
    "    #_, index_targets = torch.max(targets, dim=1)\n",
    "    #_, index_predictions = torch.max(predictions, dim=1)\n",
    "    \n",
    "    loss += criterion(predictions, targets)\n",
    "    #loss += criterion(predictions, index_targets)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, batch_size, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()#nn.NLLLoss()#          \n",
    "\n",
    "    for iter in range(1, n_iters + 1):                \n",
    "        enc_input, dec_input, targets = generate_tsp_batch(batch_size)\n",
    "        \n",
    "        targets = Variable(targets, volatile=True)\n",
    "        \n",
    "        loss = train(enc_input, dec_input, batch_size, targets, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        #plays role of embedding of D=hidden_size\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.embedding.weight = torch.nn.init.xavier_uniform(self.embedding.weight)\n",
    "        \n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "#         for param in self.rnn.parameters():\n",
    "#             nn.init.uniform(param, -0.08, 0.08)\n",
    "        \n",
    "    #Input contains the sequence at time t for the mini-batch\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        embedded = self.embedding(Variable(input.float())).view(1, self.batch_size, self.hidden_size)\n",
    "        embedded = self.dropout(embedded)  \n",
    "        \n",
    "        #embedded = Variable(input.float()).view(1, self.batch_size, self.input_size)       \n",
    "        output, hidden = self.rnn(embedded, hidden)  \n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        #result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        result = (Variable(torch.zeros(1, self.batch_size, self.hidden_size)),\n",
    "          Variable(torch.zeros((1, self.batch_size, self.hidden_size))))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtrDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, batch_size, sequence_length=10, dropout_p=0.1):\n",
    "        super(PtrDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size        \n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.attn2 = nn.Linear(self.hidden_size * 2, self.hidden_size) #as in the paper\n",
    "        self.attn2.weight = torch.nn.init.xavier_uniform(self.attn2.weight)\n",
    "                \n",
    "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size)       \n",
    "        self.V = nn.Parameter(torch.rand(self.hidden_size, 1))\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        #plays role of embedding of D=hidden_size\n",
    "        self.embedding = nn.Linear(output_size, hidden_size)\n",
    "        self.embedding.weight = torch.nn.init.xavier_uniform(self.embedding.weight)\n",
    "        \n",
    "#         for param in self.rnn.parameters():\n",
    "#             nn.init.uniform(param, -0.08, 0.08)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):                \n",
    "                \n",
    "        #embedded = Variable(input.float()).view(1, self.batch_size, self.output_size)    \n",
    "        embedded = self.embedding(Variable(input.float())).view(1, self.batch_size, self.hidden_size)\n",
    "        embedded = self.dropout(embedded)  \n",
    "        \n",
    "        repeated_hidden = hidden[0].repeat(self.sequence_length, 1, 1)\n",
    "\n",
    "        input_alignment = torch.cat((repeated_hidden, encoder_outputs), 2)                \n",
    "        \n",
    "        non_linearity = F.tanh(self.attn2(input_alignment)).squeeze()                           \n",
    "                \n",
    "        to_softmax = torch.matmul(non_linearity, self.V)\n",
    "        \n",
    "        #Compute the attention weights as in Dima's paper\n",
    "        es = F.softmax(to_softmax, dim = 0)\n",
    "        attn_weights = torch.transpose(es, 0, 1)                      \n",
    "        \n",
    "        output, hidden = self.rnn(embedded, hidden)            \n",
    "                \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        #1 because we are doing one line of the sequence at a time\n",
    "        result = (Variable(torch.zeros(1, self.batch_size, self.hidden_size)),\n",
    "            Variable(torch.zeros((1, self.batch_size, self.hidden_size))))\n",
    "        \n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 26s (- 70m 45s) (100 2%) 0.0013\n",
      "2m 52s (- 68m 48s) (200 4%) 0.0012\n",
      "4m 17s (- 67m 12s) (300 6%) 0.0012\n",
      "10m 20s (- 118m 55s) (400 8%) 0.0013\n",
      "11m 47s (- 106m 8s) (500 10%) 0.0013\n",
      "13m 12s (- 96m 48s) (600 12%) 0.0012\n",
      "14m 41s (- 90m 17s) (700 14%) 0.0012\n",
      "16m 8s (- 84m 46s) (800 16%) 0.0012\n",
      "17m 37s (- 80m 16s) (900 18%) 0.0012\n",
      "19m 1s (- 76m 6s) (1000 20%) 0.0012\n",
      "20m 29s (- 72m 38s) (1100 22%) 0.0012\n",
      "21m 53s (- 69m 20s) (1200 24%) 0.0012\n",
      "23m 17s (- 66m 18s) (1300 26%) 0.0012\n",
      "24m 45s (- 63m 40s) (1400 28%) 0.0012\n",
      "26m 12s (- 61m 8s) (1500 30%) 0.0012\n",
      "27m 37s (- 58m 41s) (1600 32%) 0.0012\n",
      "29m 2s (- 56m 21s) (1700 34%) 0.0012\n",
      "30m 35s (- 54m 22s) (1800 36%) 0.0012\n",
      "32m 1s (- 52m 14s) (1900 38%) 0.0012\n",
      "33m 30s (- 50m 15s) (2000 40%) 0.0012\n",
      "34m 55s (- 48m 13s) (2100 42%) 0.0012\n",
      "36m 27s (- 46m 24s) (2200 44%) 0.0012\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 64 #8 works well\n",
    "# encoder = EncoderRNN(input_size=2, hidden_size=hidden_size, batch_size=batch_size)\n",
    "# attn_decoder = PtrDecoderRNN(hidden_size=hidden_size, output_size=2, batch_size=batch_size)\n",
    "\n",
    "# if use_cuda:\n",
    "#     encoder2 = encoder1.cuda()\n",
    "#     attn_decoder2 = attn_decoder1.cuda()\n",
    "\n",
    "#trainIters(encoder, attn_decoder, 50000, print_every=1000, learning_rate=0.0001) #For NLLoss\n",
    "#For MSELoss:0.001, 0.0001, 0.00001 after 50,000 updates\n",
    "trainIters(encoder, attn_decoder, batch_size, 5000, print_every=100, learning_rate=0.0001) \n",
    "#p, t = evaluate(encoder, attn_decoder, 1)\n",
    "#10,000 updates -> 0.007 from 0.0084\n",
    "\n",
    "#print (np.round(p.data.numpy(),1), t)\n",
    "\n",
    "# _, index_target = torch.max(t, dim=1)\n",
    "# _, index_prediction = torch.max(p, dim=1)\n",
    "# print (index_target)\n",
    "# print (index_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t = evaluate(encoder, attn_decoder, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 2 1 4 7 7 9 8 9]\n",
      "[0 9 8 7 3 4 5 1 2 6]\n",
      "Error rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "num_batches = 1\n",
    "num_errors = 0.0\n",
    "\n",
    "for j in range(num_batches):\n",
    "\n",
    "    p, t = evaluate(encoder, attn_decoder, batch_size)\n",
    "    \n",
    "    p = torch.transpose(p, 0, 1)\n",
    "    t = torch.transpose(t, 0, 1)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #prediction = torch.transpose(p.data, 0, 1)[i].numpy().argmax(axis=1)\n",
    "        #target = t.data[i].numpy().argmax(axis=1)                \n",
    "        \n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "            print (p[i].data.numpy().argmax(axis=1))\n",
    "            print (t[i].numpy().argmax(axis=1))\n",
    "#         if (prediction == target).all() == False:\n",
    "#             print (prediction)\n",
    "#             print (target)\n",
    "#             print (\"--\")\n",
    "#             num_errors +=1\n",
    "        \n",
    "print (\"Error rate: \", num_errors/(num_batches*batch_size)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, batch_size):\n",
    "    enc_input, dec_input, targets = generate_tsp_batch(batch_size)      \n",
    "    \n",
    "    dec_input = enc_input # we don't want to feed the answer\n",
    "        \n",
    "    input_length = dec_input.size()[0]\n",
    "    target_length = dec_input.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(input_length, batch_size, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    #Pass every token to the encoder, one at a time\n",
    "    #The output is stored for when we use attention\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            enc_input[ei], encoder_hidden)\n",
    "        \n",
    "        #print (encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0]\n",
    "\n",
    "    #The first hidden state of the decoder is the last hidden state of the encoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for di in range(target_length):\n",
    "\n",
    "        decoder_input = dec_input[di]\n",
    "\n",
    "        decoder_output, decoder_hidden, decoder_attention = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    \n",
    "        predictions.append(decoder_attention)\n",
    "    \n",
    "    #Compare the one-hot vectors with predictions\n",
    "    predictions = torch.stack(predictions).squeeze()\n",
    "    \n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "batch_size = 1\n",
    "dataset = DataGenerator()\n",
    "enc_input, dec_input, targets = dataset.next_batch(batch_size, seq_len)\n",
    "print(\"batch_size\", batch_size, \"seq_len\", seq_len)\n",
    "print(\"-------------encoder input-------------\")\n",
    "print(enc_input.shape)\n",
    "print(enc_input)\n",
    "print(\"-------------decoder input-------------\")\n",
    "print(dec_input.shape)\n",
    "print(dec_input)\n",
    "print(\"-------------   targets   -------------\")\n",
    "print(targets.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.3759  0.1582  0.8439\n",
      "-1.0646 -0.2280 -0.2801\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3477  0.1061  0.0446\n",
      "  0.1848 -0.0446 -0.2955\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 1.0165 -0.0799  0.1245\n",
      "-1.4291  0.3612  1.2956\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.2771  0.0416 -0.1618\n",
      "  0.2204  0.2445 -0.4466\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.4057 -1.3889 -0.0718\n",
      " 0.3829 -0.1459  0.7754\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.2205  0.0333 -0.2364\n",
      "  0.2669  0.1927 -0.3731\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.1505  0.8445  0.3930\n",
      " 0.9456 -0.5531  1.7102\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.3307  0.1239 -0.2493\n",
      "  0.4191  0.1463 -0.4073\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n",
      "Variable containing:\n",
      " 0.5124 -1.8215 -0.5779\n",
      "-0.1179  0.4724  2.4272\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "out Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.1345  0.0521 -0.2440\n",
      "  0.5298  0.1887 -0.5275\n",
      "[torch.FloatTensor of size 1x2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [Variable(torch.randn((2, 3)))\n",
    "          for _ in range(5)]  # my sequence has five elements of 3 dimensions\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (Variable(torch.randn(1, 2, 3)),\n",
    "          Variable(torch.randn((1, 2, 3))))\n",
    "for i in inputs:\n",
    "    \n",
    "    print (i)\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 2, -1), hidden)\n",
    "    \n",
    "    print (\"out\", out)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "# inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "# hidden = (Variable(torch.randn(1, 1, 3)), Variable(\n",
    "#     torch.randn((1, 1, 3))))  # clean out hidden state\n",
    "# out, hidden = lstm(inputs, hidden)\n",
    "\n",
    "# print (\"---\")\n",
    "# print(out)\n",
    "# print(hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
